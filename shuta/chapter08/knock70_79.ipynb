{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 第8章: ニューラルネット\n",
        "\n",
        "第6章で取り組んだニュース記事のカテゴリ分類を題材として，ニューラルネットワークでカテゴリ分類モデルを実装する．なお，この章ではPyTorch, TensorFlow, Chainerなどの機械学習プラットフォームを活用せよ．"
      ],
      "metadata": {
        "id": "2yngkOZumoER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#colabを利用する上での前準備\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-0AqQjdfnNC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ed75b89-e55d-4ad5-b588-4b15c609e4c4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd '/content/drive/MyDrive'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09Y_OvUWm_Lh",
        "outputId": "c68709dc-8f2d-4954-f4e0-764645bcae5a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8qcpBddnWxy",
        "outputId": "f0b8a117-d2cd-451b-8b12-88d7fec1a080"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.10.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 70. 単語ベクトルの和による特徴量\n",
        "\n",
        "問題50で構築した学習データ，検証データ，評価データを行列・ベクトルに変換したい．例えば，学習データについて，すべての事例xi\n",
        "の特徴ベクトルxi\n",
        "を並べた行列X\n",
        "と，正解ラベルを並べた行列（ベクトル）Y\n",
        "を作成したい．\n",
        "\n",
        "ここで，n\n",
        "は学習データの事例数であり，xi∈ℝd\n",
        "とyi∈ℕ\n",
        "はそれぞれ，i∈{1,…,n}\n",
        "番目の事例の特徴量ベクトルと正解ラベルを表す． なお，今回は「ビジネス」「科学技術」「エンターテイメント」「健康」の4カテゴリ分類である．ℕ<4\n",
        "で4\n",
        "未満の自然数（0\n",
        "を含む）を表すことにすれば，任意の事例の正解ラベルyi\n",
        "はyi∈ℕ<4\n",
        "で表現できる． 以降では，ラベルの種類数をL\n",
        "で表す（今回の分類タスクではL=4\n",
        "である）．\n",
        "\n",
        "i\n",
        "番目の事例の特徴ベクトルxi\n",
        "は，次式で求める．\n",
        "\n",
        "ここで，i\n",
        "番目の事例はTi\n",
        "個の（記事見出しの）単語列(wi,1,wi,2,…,wi,Ti)\n",
        "から構成され，emb(w)∈ℝd\n",
        "は単語w\n",
        "に対応する単語ベクトル（次元数はd\n",
        "）である．すなわち，i\n",
        "番目の事例の記事見出しを，その見出しに含まれる単語のベクトルの平均で表現したものがxi\n",
        "である．今回は単語ベクトルとして，問題60でダウンロードしたものを用いればよい．300\n",
        "次元の単語ベクトルを用いたので，d=300\n",
        "である．\n",
        "\n",
        "i\n",
        "番目の事例のラベルyi\n",
        "は，次のように定義する．\n",
        "\n",
        "なお，カテゴリ名とラベルの番号が一対一で対応付いていれば，上式の通りの対応付けでなくてもよい．\n",
        "\n",
        "以上の仕様に基づき，以下の行列・ベクトルを作成し，ファイルに保存せよ．\n",
        "\n",
        "学習データの特徴量行列: Xtrain∈ℝNt×d\n",
        "学習データのラベルベクトル: Ytrain∈ℕNt\n",
        "検証データの特徴量行列: Xvalid∈ℝNv×d\n",
        "検証データのラベルベクトル: Yvalid∈ℕNv\n",
        "評価データの特徴量行列: Xtest∈ℝNe×d\n",
        "評価データのラベルベクトル: Ytest∈ℕNe\n",
        "なお，Nt,Nv,Ne\n",
        "はそれぞれ，学習データの事例数，検証データの事例数，評価データの事例数である．\n",
        "\n"
      ],
      "metadata": {
        "id": "6wYM4EE0mrzm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Yn8Av2BSgZeR"
      },
      "outputs": [],
      "source": [
        "#50と同様\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "#データ読み込み #エラーが出るため、タブ区切り、ラベル名を指定する\n",
        "df = pd.read_csv('./NewsAggregatorDataset/newsCorpora.csv', sep=\"\\t\", names=[\"id\", \"title\", \"url\", \"publisher\", \"category\", \"story\", \"hostname\", \"timestamp\"])\n",
        "\n",
        "#情報源（publisher）が”Reuters”, “Huffington Post”, “Businessweek”, “Contactmusic.com”, “Daily Mail”の事例（記事）のみを抽出する\n",
        "df = df[df['publisher'].isin([\"Reuters\", \"Huffington Post\", \"Businessweek\", \"COntactmusic.com\", \"Daily Mail\"])]\n",
        "\n",
        "#抽出された事例をランダムに並び替える\n",
        "df = df.sample(frac = 1, random_state = 42, ignore_index=True)\n",
        "\n",
        "#抽出された事例の80%を学習データ，残りの10%ずつを検証データと評価データに分割し，それぞれtrain.txt，valid.txt，test.txtというファイル名で保存する\n",
        "train, test = train_test_split(df, test_size=0.2, random_state = 42)\n",
        "test, valid = train_test_split(test, test_size=0.5, random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#60と同様\n",
        "\n",
        "import gensim\n",
        "\n",
        "model = gensim.models.KeyedVectors.load_word2vec_format('./shogi/GoogleNews-vectors-negative300.bin.gz', binary= True)"
      ],
      "metadata": {
        "id": "HnijXr3znmby"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "train['title']"
      ],
      "metadata": {
        "id": "12-HALFaoPWa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "711c2a89-b70f-43c2-d970-27a99c7e7c38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3790    So who was the Emmys' worst dressed? Lena Dunh...\n",
              "4502    Japan's Controversial Whaling Program Suspende...\n",
              "5940    Want Kate Middleton's iconic half updo? This s...\n",
              "5858    Rare Diamond Shows Earth's Interior Is All Wet...\n",
              "3334    Miley Cyrus escapes injury as her tour bus bur...\n",
              "                              ...                        \n",
              "5734    S&P 500, Dow Climb to Records on Tech Rally as...\n",
              "5191    L'Wren Scott's Death Ruled A Suicide By NYC Of...\n",
              "5390    Credit Suisse Said to Get New York Subpoena in...\n",
              "860     US web companies press demands for net neutral...\n",
              "7270    Hilary Duff Still Has 'A Lot Of Love' For Estr...\n",
              "Name: title, Length: 8804, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lis_train_vecs =[] #1文内の単語ベクトルのリスト\n",
        "tensor_vecs = [] #平均単語ベクトルのリスト\n",
        "for title in train['title']:\n",
        "  lis_train_words = title.split()\n",
        "  for word in lis_train_words:\n",
        "    try:\n",
        "      vec = model[word]\n",
        "      lis_train_vecs.append(vec)\n",
        "\n",
        "    except: #未知語の場合\n",
        "      pass\n",
        "\n",
        "  tensor_vec = torch.tensor(sum(lis_train_vecs) / len(lis_train_vecs))\n",
        "  tensor_vecs.append(tensor_vec)\n",
        "  lis_train_vecs =[]\n",
        "\n",
        "X_train = torch.stack(tensor_vecs)"
      ],
      "metadata": {
        "id": "UvueK8oZLZSC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lis_train_vecs =[] #1文内の単語ベクトルのリスト\n",
        "tensor_vecs = [] #平均単語ベクトルのリスト\n",
        "for title in valid['title']:\n",
        "  lis_train_words = title.split()\n",
        "  for word in lis_train_words:\n",
        "    try:\n",
        "      vec = model[word]\n",
        "      lis_train_vecs.append(vec)\n",
        "\n",
        "    except: #未知語の場合\n",
        "      pass\n",
        "\n",
        "  tensor_vec = torch.tensor(sum(lis_train_vecs) / len(lis_train_vecs))\n",
        "  tensor_vecs.append(tensor_vec)\n",
        "  lis_train_vecs =[]\n",
        "\n",
        "X_valid = torch.stack(tensor_vecs)"
      ],
      "metadata": {
        "id": "0LJFj-bSScIA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lis_train_vecs =[] #1文内の単語ベクトルのリスト\n",
        "tensor_vecs = [] #平均単語ベクトルのリスト\n",
        "for title in valid['title']:\n",
        "  lis_train_words = title.split()\n",
        "  for word in lis_train_words:\n",
        "    try:\n",
        "      vec = model[word]\n",
        "      lis_train_vecs.append(vec)\n",
        "\n",
        "    except: #未知語の場合\n",
        "      pass\n",
        "\n",
        "  tensor_vec = torch.tensor(sum(lis_train_vecs) / len(lis_train_vecs))\n",
        "  tensor_vecs.append(tensor_vec)\n",
        "  lis_train_vecs =[]\n",
        "\n",
        "X_test = torch.stack(tensor_vecs)"
      ],
      "metadata": {
        "id": "GDbsY0xUShR3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ターゲットのテンソル化\n",
        "category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "Y_train = torch.from_numpy(train['category'].map(category_dict).values)\n",
        "Y_valid = torch.from_numpy(valid['category'].map(category_dict).values)\n",
        "Y_test = torch.from_numpy(test['category'].map(category_dict).values)\n",
        "# 保存\n",
        "torch.save(X_train, './NewsAggregatorDataset/X_train.pt')\n",
        "torch.save(X_valid, './NewsAggregatorDataset/X_valid.pt')\n",
        "torch.save(X_test, './NewsAggregatorDataset/X_test.pt')\n",
        "torch.save(Y_train, './NewsAggregatorDataset/y_train.pt')\n",
        "torch.save(Y_valid, './NewsAggregatorDataset/y_valid.pt')\n",
        "torch.save(Y_test, './NewsAggregatorDataset/y_test.pt')"
      ],
      "metadata": {
        "id": "5Y4CEH2ENwn1"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#確認\n",
        "print(X_train)\n",
        "print(Y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LQ-9EGOCpOtC",
        "outputId": "56c22cf5-4c04-4a3b-c3ac-9cc676903fce"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0704,  0.0600,  0.0520,  ...,  0.0093,  0.1410,  0.0667],\n",
            "        [ 0.0536, -0.0164,  0.0868,  ..., -0.0089,  0.0265,  0.0666],\n",
            "        [ 0.0374,  0.0011, -0.0588,  ..., -0.0348, -0.0233, -0.0400],\n",
            "        ...,\n",
            "        [-0.0046,  0.0939, -0.0272,  ..., -0.1045, -0.0858, -0.0159],\n",
            "        [-0.0475,  0.0452, -0.0182,  ...,  0.1119, -0.0245, -0.0485],\n",
            "        [ 0.0561, -0.0307, -0.1766,  ..., -0.0750,  0.0294, -0.0518]])\n",
            "tensor([2, 1, 2,  ..., 0, 1, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 71. 単層ニューラルネットワークによる予測\n",
        "\n",
        "問題70で保存した行列を読み込み，学習データについて以下の計算を実行せよ．\n",
        "\n",
        "ただし，softmax\n",
        "はソフトマックス関数，X[1:4]∈ℝ4×d\n",
        "は特徴ベクトルx1,x2,x3,x4\n",
        "を縦に並べた行列である．\n",
        "\n",
        "行列W∈ℝd×L\n",
        "は単層ニューラルネットワークの重み行列で，ここではランダムな値で初期化すればよい（問題73以降で学習して求める）．なお，y1^∈ℝL\n",
        "は未学習の行列W\n",
        "で事例x1\n",
        "を分類したときに，各カテゴリに属する確率を表すベクトルである． 同様に，Ŷ ∈ℝn×L\n",
        "は，学習データの事例x1,x2,x3,x4\n",
        "について，各カテゴリに属する確率を行列として表現している．"
      ],
      "metadata": {
        "id": "NJmbgAt7Vu0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class SLPNet(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.fc = nn.Linear(input_size, output_size, bias=False)\n",
        "    nn.init.normal_(self.fc.weight, 0.0, 1.0)  # 正規乱数で重みを初期化\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "wMKzT6Raw5K0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SLPNet(300, 4)  # 単層ニューラルネットワークの初期化\n",
        "y_hat_1 = torch.softmax(model(X_train[:1]), dim=-1)"
      ],
      "metadata": {
        "id": "eQBDD5_GWX5h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat = torch.softmax(model.forward(X_train[:4]), dim=-1)\n",
        "print(Y_hat)\n",
        "print(Y_train[:4])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t-LhNBBHWZEr",
        "outputId": "b1655663-4d39-4cc8-ce43-388aae5e2ad9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1646, 0.4056, 0.1730, 0.2568],\n",
            "        [0.0162, 0.2099, 0.0222, 0.7517],\n",
            "        [0.2764, 0.2141, 0.0196, 0.4898],\n",
            "        [0.0090, 0.6846, 0.0639, 0.2426]], grad_fn=<SoftmaxBackward0>)\n",
            "tensor([2, 1, 2, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 72. 損失と勾配の計算\n",
        "\n",
        "学習データの事例x1\n",
        "と事例集合x1,x2,x3,x4\n",
        "に対して，クロスエントロピー損失と，行列W\n",
        "に対する勾配を計算せよ．なお，ある事例xi\n",
        "に対して損失は次式で計算される．\n",
        "\n",
        "li=−log[事例xiがyiに分類される確率]\n",
        "ただし，事例集合に対するクロスエントロピー損失は，その集合に含まれる各事例の損失の平均とする．"
      ],
      "metadata": {
        "id": "jp-eUSXvX3TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "l_1 = criterion(model(X_train[:1]), Y_train[:1])  # 入力ベクトルはsoftmax前の値\n",
        "model.zero_grad()  # 勾配をゼロで初期化\n",
        "l_1.backward()  # 勾配を計算\n",
        "print(f'損失: {l_1:.4f}')\n",
        "print(f'勾配:\\n{model.fc.weight.grad}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pz8fB97tWZr3",
        "outputId": "7af09a52-dea3-43ad-84f4-75e162368f11"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失: 1.7542\n",
            "勾配:\n",
            "tensor([[ 0.0116,  0.0099,  0.0086,  ...,  0.0015,  0.0232,  0.0110],\n",
            "        [ 0.0286,  0.0243,  0.0211,  ...,  0.0038,  0.0572,  0.0270],\n",
            "        [-0.0583, -0.0496, -0.0430,  ..., -0.0077, -0.1166, -0.0551],\n",
            "        [ 0.0181,  0.0154,  0.0134,  ...,  0.0024,  0.0362,  0.0171]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = criterion(model(X_train[:4]), Y_train[:4])\n",
        "model.zero_grad()\n",
        "l.backward()\n",
        "print(f'損失: {l:.4f}')\n",
        "print(f'勾配:\\n{model.fc.weight.grad}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40wpuW4pY7ew",
        "outputId": "5c09c1f2-fc0a-405a-eedd-8e0fd2238d96"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失: 1.9062\n",
            "勾配:\n",
            "tensor([[ 0.0056,  0.0024, -0.0016,  ..., -0.0022,  0.0045,  0.0002],\n",
            "        [ 0.0030,  0.0115, -0.0134,  ...,  0.0076,  0.0016, -0.0078],\n",
            "        [-0.0243, -0.0132,  0.0038,  ...,  0.0052, -0.0220, -0.0038],\n",
            "        [ 0.0158, -0.0008,  0.0112,  ..., -0.0105,  0.0159,  0.0113]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 73. 確率的勾配降下法による学習\n",
        "\n",
        "確率的勾配降下法（SGD: Stochastic Gradient Descent）を用いて，行列W\n",
        "を学習せよ．なお，学習は適当な基準で終了させればよい（例えば「100エポックで終了」など）．"
      ],
      "metadata": {
        "id": "MnOdqsM0Zpi5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# データセットを作成する\n",
        "import torch.utils.data as data\n",
        "\n",
        "class NewsDataset(data.Dataset):\n",
        "    \"\"\"\n",
        "    newsのDatasetクラス\n",
        "\n",
        "    Attributes\n",
        "    ----------------------------\n",
        "    X : テンソル\n",
        "        単語ベクトルの平均をまとめたテンソル\n",
        "    y : テンソル\n",
        "        カテゴリをラベル化したテンソル\n",
        "    phase : 'train' or 'val'\n",
        "        学習か訓練かを設定する\n",
        "    \"\"\"\n",
        "    def __init__(self, X, y, phase='train'):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "        self.phase = phase\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"全データサイズを返す\"\"\"\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"idxに対応するテンソル形式のデータとラベルを取得\"\"\"\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "train_dataset = NewsDataset(X_train, Y_train, phase='train')\n",
        "valid_dataset = NewsDataset(X_valid, Y_valid, phase='val')\n",
        "test_dataset = NewsDataset(X_test, Y_test, phase='val')\n",
        "\n",
        "# 動作確認\n",
        "idx = 0\n",
        "print(train_dataset.__getitem__(idx)[0].size())\n",
        "print(train_dataset.__getitem__(idx)[1])\n",
        "print(valid_dataset.__getitem__(idx)[0].size())\n",
        "print(valid_dataset.__getitem__(idx)[1])\n",
        "print(test_dataset.__getitem__(idx)[0].size())\n",
        "print(test_dataset.__getitem__(idx)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQvCDCUqY8ID",
        "outputId": "49d809d5-0cd2-4dce-9b0e-8b440dd33709"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([300])\n",
            "tensor(2)\n",
            "torch.Size([300])\n",
            "tensor(0)\n",
            "torch.Size([300])\n",
            "tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# DataLoaderを作成\n",
        "batch_size = 1\n",
        "\n",
        "train_dataloader = data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = data.DataLoader(\n",
        "            valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
        "test_dataloader = data.DataLoader(\n",
        "            test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
        "\n",
        "dataloaders_dict = {'train': train_dataloader,\n",
        "                    'val': valid_dataloader,\n",
        "                    'test': test_dataloader,\n",
        "                   }\n",
        "\n",
        "# 動作確認\n",
        "batch_iter = iter(dataloaders_dict['train'])\n",
        "inputs, labels = next(batch_iter)\n",
        "print(inputs.size())\n",
        "print(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9rNdfZwZySv",
        "outputId": "52599772-d5e6-4fc7-98cf-a15e55ef7534"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 300])\n",
            "tensor([0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "# 学習\n",
        "\n",
        "# モデルの定義\n",
        "net = SLPNet(300, 4)\n",
        "net.train()\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# 学習用の関数を定義\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {} / {}'.format(epoch + 1, num_epochs))\n",
        "        print('--------------------------------------------')\n",
        "\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train() # 訓練モード\n",
        "            else:\n",
        "                net.eval() # 検証モード\n",
        "\n",
        "            epoch_loss = 0.0 # epochの損失和\n",
        "            epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "                optimizer.zero_grad() # optimizerを初期化\n",
        "\n",
        "                # 順伝播計算(forward)\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels) # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1) # ラベルを予想\n",
        "\n",
        "                    # 訓練時は逆伝播\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # イテレーション結果の計算\n",
        "                    # lossの合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率の表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "# 学習を実行する\n",
        "num_epochs = 10\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJDAQ_c6Z7bW",
        "outputId": "dde16626-c5f3-454e-fb5d-18ad7ab6b7db"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 2133.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5779, Acc: 0.7923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 76.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4942, Acc: 0.8229\n",
            "Epoch 2 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 2032.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4054, Acc: 0.8582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 65.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4358, Acc: 0.8538\n",
            "Epoch 3 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1833.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3691, Acc: 0.8720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 115.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3989, Acc: 0.8610\n",
            "Epoch 4 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 2058.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3497, Acc: 0.8778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 30.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4054, Acc: 0.8556\n",
            "Epoch 5 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1957.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3389, Acc: 0.8823\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 88.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3918, Acc: 0.8592\n",
            "Epoch 6 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1881.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3292, Acc: 0.8849\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 107.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3883, Acc: 0.8610\n",
            "Epoch 7 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 2170.98it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3224, Acc: 0.8882\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 117.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4010, Acc: 0.8601\n",
            "Epoch 8 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 2165.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3186, Acc: 0.8900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 84.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3813, Acc: 0.8592\n",
            "Epoch 9 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1654.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3145, Acc: 0.8923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 76.42it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3797, Acc: 0.8710\n",
            "Epoch 10 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 2176.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3112, Acc: 0.8939\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 109.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3657, Acc: 0.8765\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 74. 正解率の計測\n",
        "\n",
        "問題73で求めた行列を用いて学習データおよび評価データの事例を分類したとき，その正解率をそれぞれ求めよ．"
      ],
      "metadata": {
        "id": "MnOGyMv8ajgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_acc(net, dataloader):\n",
        "    net.eval()\n",
        "    corrects = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            outputs = net(inputs)\n",
        "            _, preds = torch.max(outputs, 1) # ラベルを予想\n",
        "            corrects += torch.sum(preds == labels.data)\n",
        "    return corrects / len(dataloader.dataset)\n",
        "\n",
        "acc_train = calc_acc(net, train_dataloader)\n",
        "acc_valid = calc_acc(net, valid_dataloader)\n",
        "acc_test = calc_acc(net, test_dataloader)\n",
        "print('学習データの正解率: {:.4f}'.format(acc_train))\n",
        "print('検証データの正解率: {:.4f}'.format(acc_valid))\n",
        "print('テストデータの正解率: {:.4f}'.format(acc_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cj9uEUQpaAEJ",
        "outputId": "b4795b3d-09d7-435d-aab4-a9a153834ea3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "学習データの正解率: 0.8970\n",
            "検証データの正解率: 0.8692\n",
            "テストデータの正解率: 0.3760\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 75. 損失と正解率のプロット\n",
        "\n",
        "問題73のコードを改変し，各エポックのパラメータ更新が完了するたびに，訓練データでの損失，正解率，検証データでの損失，正解率をグラフにプロットし，学習の進捗状況を確認できるようにせよ．"
      ],
      "metadata": {
        "id": "awdlczeDmdES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習\n",
        "\n",
        "#epochごとのlossと正解率をappendするリストを用意\n",
        "epoch_loss_train_lis = []\n",
        "epoch_acc_train_lis = []\n",
        "epoch_loss_val_lis = []\n",
        "epoch_acc_val_lis = []\n",
        "\n",
        "#以下は問題73と同様\n",
        "\n",
        "# モデルの定義\n",
        "net = SLPNet(300, 4)\n",
        "net.train()\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# 学習用の関数を定義\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {} / {}'.format(epoch + 1, num_epochs))\n",
        "        print('--------------------------------------------')\n",
        "\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train() # 訓練モード\n",
        "            else:\n",
        "                net.eval() # 検証モード\n",
        "\n",
        "            epoch_loss = 0.0 # epochの損失和\n",
        "            epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "                optimizer.zero_grad() # optimizerを初期化\n",
        "\n",
        "                # 順伝播計算(forward)\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels) # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1) # ラベルを予想\n",
        "\n",
        "                    # 訓練時は逆伝播\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # イテレーション結果の計算\n",
        "                    # lossの合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率の表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "            print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # epochごとlossと正解率の表示をlistにappendする #問題75挿入箇所\n",
        "            if phase == 'train':                      #SLPNet.train():訓練モードの場合、訓練データのlossとaccuracyを求める\n",
        "              epoch_loss_train_lis.append(epoch_loss) #epoch_lossは各エポックにおけるloss\n",
        "              epoch_acc_train_lis.append(epoch_acc)   #epoch_accは各エポックにおけるaccuracy\n",
        "\n",
        "            else:  # phase == 'val'の場合              #SLPNet.eval():検証モードの場合、検証データのlossとaccuracyを求める\n",
        "              epoch_loss_val_lis.append(epoch_loss)\n",
        "              epoch_acc_val_lis.append(epoch_acc)\n",
        "\n",
        "\n",
        "# 学習を実行する\n",
        "num_epochs = 30 #エポック数は30とする\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eep0AslZV2dE",
        "outputId": "34632145-4f21-43ed-eac6-4a0bb8e40ecf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1901.02it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.5952, Acc: 0.7875\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 74.57it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.4704, Acc: 0.8338\n",
            "Epoch 2 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1548.54it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.4034, Acc: 0.8602\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 98.74it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.4292, Acc: 0.8456\n",
            "Epoch 3 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1907.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3665, Acc: 0.8710\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 109.14it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.4024, Acc: 0.8556\n",
            "Epoch 4 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1905.86it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3485, Acc: 0.8778\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 48.27it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3846, Acc: 0.8619\n",
            "Epoch 5 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1557.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3361, Acc: 0.8838\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 83.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3743, Acc: 0.8674\n",
            "Epoch 6 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1944.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3280, Acc: 0.8876\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 80.16it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3705, Acc: 0.8683\n",
            "Epoch 7 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1821.80it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3211, Acc: 0.8882\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 58.19it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3749, Acc: 0.8674\n",
            "Epoch 8 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1628.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3177, Acc: 0.8890\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 113.32it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3612, Acc: 0.8701\n",
            "Epoch 9 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1928.96it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3135, Acc: 0.8927\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 71.48it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3742, Acc: 0.8656\n",
            "Epoch 10 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1765.01it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3097, Acc: 0.8918\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 50.82it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3658, Acc: 0.8710\n",
            "Epoch 11 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1660.43it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3078, Acc: 0.8933\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 109.36it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3640, Acc: 0.8656\n",
            "Epoch 12 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1922.17it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3061, Acc: 0.8948\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 95.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3644, Acc: 0.8710\n",
            "Epoch 13 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1678.89it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3037, Acc: 0.8935\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 72.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3706, Acc: 0.8710\n",
            "Epoch 14 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1741.44it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3016, Acc: 0.8972\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 80.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3753, Acc: 0.8656\n",
            "Epoch 15 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1920.56it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.3014, Acc: 0.8930\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 114.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3845, Acc: 0.8647\n",
            "Epoch 16 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1643.29it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2992, Acc: 0.8964\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 51.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3564, Acc: 0.8747\n",
            "Epoch 17 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1799.66it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2995, Acc: 0.8946\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 73.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3692, Acc: 0.8765\n",
            "Epoch 18 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1915.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2970, Acc: 0.8958\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 95.14it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3653, Acc: 0.8774\n",
            "Epoch 19 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1558.08it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2974, Acc: 0.8973\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 64.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3672, Acc: 0.8728\n",
            "Epoch 20 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1877.30it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2963, Acc: 0.8979\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 79.50it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3884, Acc: 0.8692\n",
            "Epoch 21 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1922.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2953, Acc: 0.8994\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 111.87it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3822, Acc: 0.8674\n",
            "Epoch 22 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1527.35it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2952, Acc: 0.8973\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 107.85it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3716, Acc: 0.8692\n",
            "Epoch 23 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1925.51it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2941, Acc: 0.8953\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 111.61it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3828, Acc: 0.8665\n",
            "Epoch 24 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1932.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2932, Acc: 0.8988\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 76.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3665, Acc: 0.8747\n",
            "Epoch 25 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1544.64it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2926, Acc: 0.8985\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 101.55it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3602, Acc: 0.8710\n",
            "Epoch 26 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1970.46it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2931, Acc: 0.8986\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 112.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3630, Acc: 0.8719\n",
            "Epoch 27 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1944.72it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2922, Acc: 0.8989\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 83.41it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3704, Acc: 0.8765\n",
            "Epoch 28 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:05<00:00, 1551.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2910, Acc: 0.8993\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 107.10it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3718, Acc: 0.8701\n",
            "Epoch 29 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1939.93it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.2912, Acc: 0.8994\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 78.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "val Loss: 0.3650, Acc: 0.8719\n",
            "Epoch 30 / 30\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:04<00:00, 1873.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.2911, Acc: 0.9002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 65.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3690, Acc: 0.8728\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 視覚化\n",
        "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
        "ax[0].plot(epoch_loss_train_lis, label='train')\n",
        "ax[0].plot(epoch_loss_val_lis, label='valid')\n",
        "ax[0].set_xlabel('epoch')\n",
        "ax[0].set_ylabel('loss')\n",
        "ax[0].legend()\n",
        "ax[1].plot(epoch_acc_train_lis, label='train')\n",
        "ax[1].plot(epoch_acc_val_lis, label='valid')\n",
        "ax[1].set_xlabel('epoch')\n",
        "ax[1].set_ylabel('accuracy')\n",
        "ax[1].legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 464
        },
        "id": "NNJlY1mvUrJj",
        "outputId": "78ff2edd-ac4e-495d-c7ea-15e1ae8e58b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 76. チェックポイント\n",
        "\n",
        "問題75のコードを改変し，各エポックのパラメータ更新が完了するたびに，チェックポイント（学習途中のパラメータ（重み行列など）の値や最適化アルゴリズムの内部状態）をファイルに書き出せ．"
      ],
      "metadata": {
        "id": "_S6xKoFlUsvy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#学習途中のパラメータはnet.state_dict()、最適化アルゴリズムのバイブ状態はoptimizer.state_dict()でアクセス可能。\n",
        "\n",
        "# モデルの定義\n",
        "net = SLPNet(300, 4)\n",
        "net.train()\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# 学習用の関数を定義\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {} / {}'.format(epoch + 1, num_epochs))\n",
        "        print('--------------------------------------------')\n",
        "\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train() # 訓練モード\n",
        "            else:\n",
        "                net.eval() # 検証モード\n",
        "\n",
        "            epoch_loss = 0.0 # epochの損失和\n",
        "            epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "                optimizer.zero_grad() # optimizerを初期化\n",
        "\n",
        "                # 順伝播計算(forward)\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels) # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1) # ラベルを予想\n",
        "\n",
        "                    # 訓練時は逆伝播\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # イテレーション結果の計算\n",
        "                    # lossの合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                    # チェックポイントの保存\n",
        "                    torch.save({'epoch': epoch, 'model_state_dict': net.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n",
        "\n",
        "# 学習を実行する\n",
        "num_epochs = 10 #エポック数は10とする\n",
        "train_model(net, dataloaders_dict, criterion, optimizer, num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOu0wXov2FJg",
        "outputId": "188e4c7d-e8a1-4db9-eb0d-81ae3e95aacb"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:58<00:00, 149.65it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 29.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:53<00:00, 164.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 39.40it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:54<00:00, 162.98it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.25it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:56<00:00, 157.11it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 63.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:53<00:00, 163.09it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 27.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:54<00:00, 160.88it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 72.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:55<00:00, 159.29it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 35.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:54<00:00, 162.73it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 56.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:54<00:00, 162.09it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 79.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 / 10\n",
            "--------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:53<00:00, 163.28it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 62.14it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 77. ミニバッチ化\n",
        "\n",
        "問題76のコードを改変し，B\n",
        "事例ごとに損失・勾配を計算し，行列W\n",
        "の値を更新せよ（ミニバッチ化）．B\n",
        "の値を1,2,4,8,…\n",
        "と変化させながら，1エポックの学習に要する時間を比較せよ．"
      ],
      "metadata": {
        "id": "Z06NDvYZmYZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "#epochごとのlossと正解率をappendするリストを用意\n",
        "epoch_loss_train_lis = []\n",
        "epoch_acc_train_lis = []\n",
        "epoch_loss_val_lis = []\n",
        "epoch_acc_val_lis = []\n",
        "\n",
        "def model(train_dataset, valid_dataset, batch_size, net, criterion, optimizer, num_epochs):\n",
        "\n",
        "  # DataLoaderを作成\n",
        "  train_dataloader = data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  valid_dataloader = data.DataLoader(\n",
        "            valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
        "\n",
        "  # 学習\n",
        "  for epoch in range(num_epochs):\n",
        "    # 開始時刻の記録\n",
        "    s_time =time.time()\n",
        "\n",
        "\n",
        "    # epochごとの学習と検証のループ\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            net.train() # 訓練モード\n",
        "        else:\n",
        "            net.eval() # 検証モード\n",
        "\n",
        "        epoch_loss = 0.0 # epochの損失和\n",
        "        epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "        # データローダーからミニバッチを取り出すループ\n",
        "        for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "            optimizer.zero_grad() # optimizerを初期化\n",
        "\n",
        "            # 順伝播計算(forward)\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels) # 損失を計算\n",
        "                _, preds = torch.max(outputs, 1) # ラベルを予想\n",
        "\n",
        "                # 訓練時は逆伝播\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # イテレーション結果の計算\n",
        "                # lossの合計を更新\n",
        "                epoch_loss += loss.item() * inputs.size(0)\n",
        "                # 正解数の合計を更新\n",
        "                epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # チェックポイントの保存\n",
        "                torch.save({'epoch': epoch, 'model_state_dict': net.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n",
        "\n",
        "        # epochごとのlossと正解率の表示\n",
        "        epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "        epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "        # epochごとlossと正解率の表示をlistにappendする #問題75挿入箇所\n",
        "        if phase == 'train':\n",
        "          epoch_loss_train_lis.append(epoch_loss)\n",
        "          epoch_acc_train_lis.append(epoch_acc)\n",
        "\n",
        "        else:  # phase == 'test'の場合\n",
        "          epoch_loss_val_lis.append(epoch_loss)\n",
        "          epoch_acc_val_lis.append(epoch_acc)\n",
        "\n",
        "        print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "        # 終了時刻の記録\n",
        "        e_time = time.time()\n",
        "        calc_time = e_time - s_time\n",
        "        print('batch_size {} calc_time: {:.4f} sec'.format(batch_size, calc_time))\n",
        "\n",
        "  return epoch_loss_train_lis, epoch_acc_train_lis, epoch_loss_val_lis, epoch_acc_val_lis, calc_time\n",
        "\n",
        "# データセットの作成\n",
        "train_dataset = NewsDataset(X_train, Y_train, phase='train')\n",
        "valid_dataset = NewsDataset(X_valid, Y_valid, phase='val')\n",
        "test_dataset = NewsDataset(X_test, Y_test, phase='val')\n",
        "\n",
        "# モデルの定義\n",
        "net = SLPNet(300, 4)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# モデルの学習\n",
        "for batch_size in [2 ** i for i in range(11)]:\n",
        "  print(f'バッチサイズ: {batch_size}')\n",
        "  log = model(train_dataset, valid_dataset, batch_size, net, criterion, optimizer, 1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdieLxh9LUbb",
        "outputId": "c59a82e4-e13c-4bb1-db8a-3f5804132532"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "バッチサイズ: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:56<00:00, 154.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5658, Acc: 0.7940\n",
            "batch_size 1 calc_time: 56.9914 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 43.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4460, Acc: 0.8429\n",
            "batch_size 1 calc_time: 57.0257 sec\n",
            "バッチサイズ: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:55<00:00, 157.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3967, Acc: 0.8610\n",
            "batch_size 2 calc_time: 55.8417 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 55.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4013, Acc: 0.8610\n",
            "batch_size 2 calc_time: 55.8688 sec\n",
            "バッチサイズ: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [01:00<00:00, 144.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3637, Acc: 0.8745\n",
            "batch_size 4 calc_time: 60.8520 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 31.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3869, Acc: 0.8638\n",
            "batch_size 4 calc_time: 60.8955 sec\n",
            "バッチサイズ: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:57<00:00, 153.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3469, Acc: 0.8808\n",
            "batch_size 8 calc_time: 57.2715 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 63.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3794, Acc: 0.8592\n",
            "batch_size 8 calc_time: 57.2970 sec\n",
            "バッチサイズ: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:58<00:00, 151.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3352, Acc: 0.8838\n",
            "batch_size 16 calc_time: 58.3117 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 67.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3707, Acc: 0.8719\n",
            "batch_size 16 calc_time: 58.3366 sec\n",
            "バッチサイズ: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:55<00:00, 157.39it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3274, Acc: 0.8872\n",
            "batch_size 32 calc_time: 55.9454 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 62.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3607, Acc: 0.8728\n",
            "batch_size 32 calc_time: 55.9723 sec\n",
            "バッチサイズ: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:55<00:00, 159.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3226, Acc: 0.8876\n",
            "batch_size 64 calc_time: 55.2223 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 36.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3633, Acc: 0.8665\n",
            "batch_size 64 calc_time: 55.2575 sec\n",
            "バッチサイズ: 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:55<00:00, 159.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3171, Acc: 0.8894\n",
            "batch_size 128 calc_time: 55.1654 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 29.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3678, Acc: 0.8710\n",
            "batch_size 128 calc_time: 55.2127 sec\n",
            "バッチサイズ: 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:55<00:00, 157.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3127, Acc: 0.8920\n",
            "batch_size 256 calc_time: 55.8445 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 52.17it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3587, Acc: 0.8701\n",
            "batch_size 256 calc_time: 55.8741 sec\n",
            "バッチサイズ: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:54<00:00, 161.52it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3103, Acc: 0.8939\n",
            "batch_size 512 calc_time: 54.5177 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 82.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3613, Acc: 0.8701\n",
            "batch_size 512 calc_time: 54.5410 sec\n",
            "バッチサイズ: 1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:55<00:00, 159.49it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3060, Acc: 0.8936\n",
            "batch_size 1024 calc_time: 55.2143 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 75.03it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3752, Acc: 0.8719\n",
            "batch_size 1024 calc_time: 55.2361 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 78. GPU上での学習\n",
        "\n",
        "問題77のコードを改変し，GPU上で学習を実行せよ．"
      ],
      "metadata": {
        "id": "XWNpTy9Kmthq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "#epochごとのlossと正解率をappendするリストを用意\n",
        "epoch_loss_train_lis = []\n",
        "epoch_acc_train_lis = []\n",
        "epoch_loss_val_lis = []\n",
        "epoch_acc_val_lis = []\n",
        "\n",
        "def model(train_dataset, valid_dataset, batch_size, net, criterion, optimizer, num_epochs, device=None):\n",
        "  # GPUに送る\n",
        "  net.to(device) #追加\n",
        "\n",
        "  # DataLoaderを作成\n",
        "  train_dataloader = data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True)\n",
        "  valid_dataloader = data.DataLoader(\n",
        "            valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
        "\n",
        "  # 学習\n",
        "  for epoch in range(num_epochs):\n",
        "    # 開始時刻の記録\n",
        "    s_time =time.time()\n",
        "\n",
        "\n",
        "    # epochごとの学習と検証のループ\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            net.train() # 訓練モード\n",
        "        else:\n",
        "            net.eval() # 検証モード\n",
        "\n",
        "        epoch_loss = 0.0 # epochの損失和\n",
        "        epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "        # データローダーからミニバッチを取り出すループ\n",
        "        for inputs, labels in tqdm(dataloaders_dict[phase]):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "            optimizer.zero_grad() # optimizerを初期化\n",
        "\n",
        "            # 順伝播計算(forward)\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = net(inputs)\n",
        "                loss = criterion(outputs, labels) # 損失を計算\n",
        "                _, preds = torch.max(outputs, 1) # ラベルを予想\n",
        "\n",
        "                # 訓練時は逆伝播\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                # イテレーション結果の計算\n",
        "                # lossの合計を更新\n",
        "                epoch_loss += loss.item() * inputs.size(0)\n",
        "                # 正解数の合計を更新\n",
        "                epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "                # チェックポイントの保存\n",
        "                torch.save({'epoch': epoch, 'model_state_dict': net.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n",
        "\n",
        "        # epochごとのlossと正解率の表示\n",
        "        epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "        epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "\n",
        "        # epochごとlossと正解率の表示をlistにappendする #問題75挿入箇所\n",
        "        if phase == 'train':\n",
        "          epoch_loss_train_lis.append(epoch_loss)\n",
        "          epoch_acc_train_lis.append(epoch_acc)\n",
        "\n",
        "        else:  # phase == 'test'の場合\n",
        "          epoch_loss_val_lis.append(epoch_loss)\n",
        "          epoch_acc_val_lis.append(epoch_acc)\n",
        "\n",
        "        print('{} Loss: {:.4f}, Acc: {:.4f}'.format(phase, epoch_loss, epoch_acc))\n",
        "\n",
        "        # 終了時刻の記録\n",
        "        e_time = time.time()\n",
        "        calc_time = e_time - s_time\n",
        "        print('batch_size {} calc_time: {:.4f} sec'.format(batch_size, calc_time))\n",
        "\n",
        "  return epoch_loss_train_lis, epoch_acc_train_lis, epoch_loss_val_lis, epoch_acc_val_lis, calc_time\n",
        "\n",
        "# データセットの作成\n",
        "train_dataset = NewsDataset(X_train, Y_train, phase='train')\n",
        "valid_dataset = NewsDataset(X_valid, Y_valid, phase='val')\n",
        "test_dataset = NewsDataset(X_test, Y_test, phase='val')\n",
        "\n",
        "# モデルの定義\n",
        "net = SLPNet(300, 4)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01, momentum=0.9)\n",
        "\n",
        "# デバイスの指定\n",
        "device = torch.device('cuda')\n",
        "\n",
        "# モデルの学習\n",
        "for batch_size in [2 ** i for i in range(11)]:\n",
        "  print(f'バッチサイズ: {batch_size}')\n",
        "  log = model(train_dataset, valid_dataset, batch_size, net, criterion, optimizer, 1, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khWr27C3Nuyf",
        "outputId": "17ccd1d7-1a0a-495a-e98c-705906681d23"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "バッチサイズ: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:53<00:00, 164.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5763, Acc: 0.7950\n",
            "batch_size 1 calc_time: 53.4732 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 70.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4470, Acc: 0.8429\n",
            "batch_size 1 calc_time: 53.4941 sec\n",
            "バッチサイズ: 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:50<00:00, 173.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4021, Acc: 0.8570\n",
            "batch_size 2 calc_time: 50.6350 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 78.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4026, Acc: 0.8538\n",
            "batch_size 2 calc_time: 50.6573 sec\n",
            "バッチサイズ: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:48<00:00, 180.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3666, Acc: 0.8713\n",
            "batch_size 4 calc_time: 48.8770 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 72.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3989, Acc: 0.8529\n",
            "batch_size 4 calc_time: 48.8989 sec\n",
            "バッチサイズ: 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:49<00:00, 179.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3480, Acc: 0.8790\n",
            "batch_size 8 calc_time: 49.1196 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 81.18it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3755, Acc: 0.8647\n",
            "batch_size 8 calc_time: 49.1401 sec\n",
            "バッチサイズ: 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:48<00:00, 180.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3379, Acc: 0.8841\n",
            "batch_size 16 calc_time: 48.8703 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 52.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3769, Acc: 0.8638\n",
            "batch_size 16 calc_time: 48.8980 sec\n",
            "バッチサイズ: 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:48<00:00, 180.66it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3296, Acc: 0.8845\n",
            "batch_size 32 calc_time: 48.7468 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 84.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3656, Acc: 0.8728\n",
            "batch_size 32 calc_time: 48.7691 sec\n",
            "バッチサイズ: 64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:49<00:00, 179.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3233, Acc: 0.8863\n",
            "batch_size 64 calc_time: 49.1212 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 78.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3620, Acc: 0.8710\n",
            "batch_size 64 calc_time: 49.1412 sec\n",
            "バッチサイズ: 128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:49<00:00, 177.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3179, Acc: 0.8900\n",
            "batch_size 128 calc_time: 49.5271 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 65.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3606, Acc: 0.8701\n",
            "batch_size 128 calc_time: 49.5556 sec\n",
            "バッチサイズ: 256\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:48<00:00, 179.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3143, Acc: 0.8883\n",
            "batch_size 256 calc_time: 48.9671 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 41.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3592, Acc: 0.8719\n",
            "batch_size 256 calc_time: 48.9991 sec\n",
            "バッチサイズ: 512\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:48<00:00, 180.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3100, Acc: 0.8898\n",
            "batch_size 512 calc_time: 48.7722 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 60.67it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3673, Acc: 0.8674\n",
            "batch_size 512 calc_time: 48.7959 sec\n",
            "バッチサイズ: 1024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8804/8804 [00:48<00:00, 180.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.3093, Acc: 0.8907\n",
            "batch_size 1024 calc_time: 48.7613 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 81.14it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3606, Acc: 0.8674\n",
            "batch_size 1024 calc_time: 48.7820 sec\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 79. 多層ニューラルネットワーク\n",
        "\n",
        "問題78のコードを改変し，バイアス項の導入や多層化など，ニューラルネットワークの形状を変更しながら，高性能なカテゴリ分類器を構築せよ．"
      ],
      "metadata": {
        "id": "2F-yu6uLmzJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLNet(nn.Module):\n",
        "    def __init__(self, input_size, mid_size, output_size):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "                    nn.Linear(input_size, mid_size),\n",
        "                    nn.BatchNorm1d(mid_size),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(mid_size, mid_size),\n",
        "                    nn.BatchNorm1d(mid_size),\n",
        "                    nn.ReLU(),\n",
        "                    nn.Linear(mid_size, output_size),\n",
        "                    )\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.layers(x)\n",
        "        return logits\n",
        "\n",
        "net = MLNet(300, 256, 4)"
      ],
      "metadata": {
        "id": "OYx4OyfBbZda"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 学習用の関数を定義\n",
        "def train_model(net, dataloaders_dict, criterion, optimizer, num_epochs):\n",
        "\n",
        "    # 初期設定\n",
        "    # GPUが使えるか確認\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"使用デバイス:\", device)\n",
        "\n",
        "    # ネットワークをgpuへ\n",
        "    net.to(device)\n",
        "\n",
        "    # ネットワークがある程度固定なら高速化させる\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "    train_loss = []\n",
        "    train_acc = []\n",
        "    valid_loss = []\n",
        "    valid_acc = []\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs, eta_min=1e-6, last_epoch=-1)\n",
        "\n",
        "    # epochのループ\n",
        "    for epoch in range(num_epochs):\n",
        "        # epochごとの学習と検証のループ\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                net.train() # 訓練モード\n",
        "            else:\n",
        "                net.eval() # 検証モード\n",
        "\n",
        "            epoch_loss = 0.0 # epochの損失和\n",
        "            epoch_corrects = 0 # epochの正解数\n",
        "\n",
        "            # データローダーからミニバッチを取り出すループ\n",
        "            for inputs, labels in dataloaders_dict[phase]:\n",
        "                # GPUが使えるならGPUにおっくる\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                optimizer.zero_grad() # optimizerを初期化\n",
        "\n",
        "                # 順伝播計算(forward)\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = net(inputs)\n",
        "                    loss = criterion(outputs, labels) # 損失を計算\n",
        "                    _, preds = torch.max(outputs, 1) # ラベルを予想\n",
        "\n",
        "                    # 訓練時は逆伝播\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                    # イテレーション結果の計算\n",
        "                    # lossの合計を更新\n",
        "                    epoch_loss += loss.item() * inputs.size(0)\n",
        "                    # 正解数の合計を更新\n",
        "                    epoch_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            # epochごとのlossと正解率の表示\n",
        "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
        "            epoch_acc = epoch_corrects.double() / len(dataloaders_dict[phase].dataset)\n",
        "            if phase == 'train':\n",
        "                train_loss.append(epoch_loss)\n",
        "                train_acc.append(epoch_acc.cpu())\n",
        "            else:\n",
        "                valid_loss.append(epoch_loss)\n",
        "                valid_acc.append(epoch_acc.cpu())\n",
        "\n",
        "        print('Epoch {} / {} (train) Loss: {:.4f}, Acc: {:.4f}, (val) Loss: {:.4f}, Acc: {:.4f}'.format(epoch + 1, num_epochs, train_loss[-1], train_acc[-1], valid_loss[-1], valid_acc[-1]))\n",
        "        scheduler.step()\n",
        "    return train_loss, train_acc, valid_loss, valid_acc\n",
        "\n",
        "batch_size = 2048\n",
        "num_epochs = 200\n",
        "\n",
        "# DataLoaderを作成\n",
        "train_dataloader = data.DataLoader(\n",
        "            train_dataset, batch_size=batch_size, shuffle=True)\n",
        "valid_dataloader = data.DataLoader(\n",
        "            valid_dataset, batch_size=len(valid_dataset), shuffle=False)\n",
        "test_dataloader = data.DataLoader(\n",
        "            test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
        "\n",
        "dataloaders_dict = {'train': train_dataloader,\n",
        "                    'val': valid_dataloader,\n",
        "                    'test': test_dataloader,\n",
        "                   }\n",
        "# モデルの定義\n",
        "net = MLNet(300, 256, 4)\n",
        "net.train()\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# 最適化手法の定義\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
        "\n",
        "train_loss, train_acc, valid_loss, valid_acc = \\\n",
        "            train_model(net, dataloaders_dict, criterion, optimizer,\n",
        "                        num_epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JwPODtsVbz5x",
        "outputId": "0ac01fe2-0967-4b10-92ab-5ba4b815364f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "使用デバイス: cuda:0\n",
            "Epoch 1 / 200 (train) Loss: 1.3285, Acc: 0.3670, (val) Loss: 1.3449, Acc: 0.5213\n",
            "Epoch 2 / 200 (train) Loss: 1.1573, Acc: 0.5725, (val) Loss: 1.3093, Acc: 0.5213\n",
            "Epoch 3 / 200 (train) Loss: 1.0193, Acc: 0.6824, (val) Loss: 1.2674, Acc: 0.5204\n",
            "Epoch 4 / 200 (train) Loss: 0.9099, Acc: 0.7274, (val) Loss: 1.2183, Acc: 0.5241\n",
            "Epoch 5 / 200 (train) Loss: 0.8226, Acc: 0.7553, (val) Loss: 1.1609, Acc: 0.5658\n",
            "Epoch 6 / 200 (train) Loss: 0.7534, Acc: 0.7764, (val) Loss: 1.0941, Acc: 0.6530\n",
            "Epoch 7 / 200 (train) Loss: 0.6971, Acc: 0.7949, (val) Loss: 1.0174, Acc: 0.7048\n",
            "Epoch 8 / 200 (train) Loss: 0.6504, Acc: 0.8084, (val) Loss: 0.9326, Acc: 0.7357\n",
            "Epoch 9 / 200 (train) Loss: 0.6119, Acc: 0.8196, (val) Loss: 0.8461, Acc: 0.7611\n",
            "Epoch 10 / 200 (train) Loss: 0.5787, Acc: 0.8294, (val) Loss: 0.7632, Acc: 0.7820\n",
            "Epoch 11 / 200 (train) Loss: 0.5503, Acc: 0.8375, (val) Loss: 0.6915, Acc: 0.8038\n",
            "Epoch 12 / 200 (train) Loss: 0.5255, Acc: 0.8458, (val) Loss: 0.6334, Acc: 0.8120\n",
            "Epoch 13 / 200 (train) Loss: 0.5040, Acc: 0.8525, (val) Loss: 0.5896, Acc: 0.8183\n",
            "Epoch 14 / 200 (train) Loss: 0.4847, Acc: 0.8579, (val) Loss: 0.5558, Acc: 0.8247\n",
            "Epoch 15 / 200 (train) Loss: 0.4671, Acc: 0.8630, (val) Loss: 0.5313, Acc: 0.8265\n",
            "Epoch 16 / 200 (train) Loss: 0.4520, Acc: 0.8665, (val) Loss: 0.5123, Acc: 0.8256\n",
            "Epoch 17 / 200 (train) Loss: 0.4383, Acc: 0.8712, (val) Loss: 0.4976, Acc: 0.8274\n",
            "Epoch 18 / 200 (train) Loss: 0.4260, Acc: 0.8740, (val) Loss: 0.4850, Acc: 0.8292\n",
            "Epoch 19 / 200 (train) Loss: 0.4148, Acc: 0.8772, (val) Loss: 0.4730, Acc: 0.8338\n",
            "Epoch 20 / 200 (train) Loss: 0.4038, Acc: 0.8802, (val) Loss: 0.4640, Acc: 0.8365\n",
            "Epoch 21 / 200 (train) Loss: 0.3945, Acc: 0.8808, (val) Loss: 0.4561, Acc: 0.8374\n",
            "Epoch 22 / 200 (train) Loss: 0.3854, Acc: 0.8840, (val) Loss: 0.4481, Acc: 0.8401\n",
            "Epoch 23 / 200 (train) Loss: 0.3769, Acc: 0.8871, (val) Loss: 0.4419, Acc: 0.8420\n",
            "Epoch 24 / 200 (train) Loss: 0.3694, Acc: 0.8879, (val) Loss: 0.4355, Acc: 0.8447\n",
            "Epoch 25 / 200 (train) Loss: 0.3622, Acc: 0.8898, (val) Loss: 0.4299, Acc: 0.8447\n",
            "Epoch 26 / 200 (train) Loss: 0.3549, Acc: 0.8912, (val) Loss: 0.4248, Acc: 0.8474\n",
            "Epoch 27 / 200 (train) Loss: 0.3481, Acc: 0.8931, (val) Loss: 0.4206, Acc: 0.8492\n",
            "Epoch 28 / 200 (train) Loss: 0.3417, Acc: 0.8946, (val) Loss: 0.4163, Acc: 0.8501\n",
            "Epoch 29 / 200 (train) Loss: 0.3359, Acc: 0.8957, (val) Loss: 0.4119, Acc: 0.8510\n",
            "Epoch 30 / 200 (train) Loss: 0.3300, Acc: 0.8989, (val) Loss: 0.4077, Acc: 0.8529\n",
            "Epoch 31 / 200 (train) Loss: 0.3246, Acc: 0.8991, (val) Loss: 0.4037, Acc: 0.8529\n",
            "Epoch 32 / 200 (train) Loss: 0.3196, Acc: 0.9021, (val) Loss: 0.4008, Acc: 0.8565\n",
            "Epoch 33 / 200 (train) Loss: 0.3145, Acc: 0.9015, (val) Loss: 0.3966, Acc: 0.8556\n",
            "Epoch 34 / 200 (train) Loss: 0.3091, Acc: 0.9038, (val) Loss: 0.3929, Acc: 0.8565\n",
            "Epoch 35 / 200 (train) Loss: 0.3046, Acc: 0.9060, (val) Loss: 0.3910, Acc: 0.8565\n",
            "Epoch 36 / 200 (train) Loss: 0.2999, Acc: 0.9075, (val) Loss: 0.3883, Acc: 0.8592\n",
            "Epoch 37 / 200 (train) Loss: 0.2959, Acc: 0.9091, (val) Loss: 0.3860, Acc: 0.8592\n",
            "Epoch 38 / 200 (train) Loss: 0.2912, Acc: 0.9114, (val) Loss: 0.3834, Acc: 0.8583\n",
            "Epoch 39 / 200 (train) Loss: 0.2873, Acc: 0.9131, (val) Loss: 0.3812, Acc: 0.8601\n",
            "Epoch 40 / 200 (train) Loss: 0.2832, Acc: 0.9142, (val) Loss: 0.3779, Acc: 0.8601\n",
            "Epoch 41 / 200 (train) Loss: 0.2792, Acc: 0.9149, (val) Loss: 0.3763, Acc: 0.8610\n",
            "Epoch 42 / 200 (train) Loss: 0.2761, Acc: 0.9169, (val) Loss: 0.3751, Acc: 0.8610\n",
            "Epoch 43 / 200 (train) Loss: 0.2710, Acc: 0.9181, (val) Loss: 0.3729, Acc: 0.8638\n",
            "Epoch 44 / 200 (train) Loss: 0.2672, Acc: 0.9196, (val) Loss: 0.3709, Acc: 0.8629\n",
            "Epoch 45 / 200 (train) Loss: 0.2633, Acc: 0.9206, (val) Loss: 0.3691, Acc: 0.8656\n",
            "Epoch 46 / 200 (train) Loss: 0.2612, Acc: 0.9214, (val) Loss: 0.3664, Acc: 0.8647\n",
            "Epoch 47 / 200 (train) Loss: 0.2565, Acc: 0.9223, (val) Loss: 0.3644, Acc: 0.8683\n",
            "Epoch 48 / 200 (train) Loss: 0.2535, Acc: 0.9249, (val) Loss: 0.3630, Acc: 0.8683\n",
            "Epoch 49 / 200 (train) Loss: 0.2499, Acc: 0.9250, (val) Loss: 0.3625, Acc: 0.8701\n",
            "Epoch 50 / 200 (train) Loss: 0.2470, Acc: 0.9259, (val) Loss: 0.3618, Acc: 0.8692\n",
            "Epoch 51 / 200 (train) Loss: 0.2440, Acc: 0.9269, (val) Loss: 0.3605, Acc: 0.8683\n",
            "Epoch 52 / 200 (train) Loss: 0.2405, Acc: 0.9281, (val) Loss: 0.3589, Acc: 0.8701\n",
            "Epoch 53 / 200 (train) Loss: 0.2378, Acc: 0.9299, (val) Loss: 0.3576, Acc: 0.8710\n",
            "Epoch 54 / 200 (train) Loss: 0.2342, Acc: 0.9321, (val) Loss: 0.3562, Acc: 0.8719\n",
            "Epoch 55 / 200 (train) Loss: 0.2308, Acc: 0.9338, (val) Loss: 0.3551, Acc: 0.8728\n",
            "Epoch 56 / 200 (train) Loss: 0.2286, Acc: 0.9350, (val) Loss: 0.3535, Acc: 0.8738\n",
            "Epoch 57 / 200 (train) Loss: 0.2258, Acc: 0.9341, (val) Loss: 0.3520, Acc: 0.8738\n",
            "Epoch 58 / 200 (train) Loss: 0.2227, Acc: 0.9364, (val) Loss: 0.3513, Acc: 0.8738\n",
            "Epoch 59 / 200 (train) Loss: 0.2204, Acc: 0.9367, (val) Loss: 0.3511, Acc: 0.8738\n",
            "Epoch 60 / 200 (train) Loss: 0.2165, Acc: 0.9396, (val) Loss: 0.3493, Acc: 0.8756\n",
            "Epoch 61 / 200 (train) Loss: 0.2139, Acc: 0.9389, (val) Loss: 0.3480, Acc: 0.8756\n",
            "Epoch 62 / 200 (train) Loss: 0.2112, Acc: 0.9405, (val) Loss: 0.3473, Acc: 0.8747\n",
            "Epoch 63 / 200 (train) Loss: 0.2083, Acc: 0.9417, (val) Loss: 0.3460, Acc: 0.8747\n",
            "Epoch 64 / 200 (train) Loss: 0.2064, Acc: 0.9422, (val) Loss: 0.3454, Acc: 0.8756\n",
            "Epoch 65 / 200 (train) Loss: 0.2037, Acc: 0.9428, (val) Loss: 0.3453, Acc: 0.8765\n",
            "Epoch 66 / 200 (train) Loss: 0.2008, Acc: 0.9453, (val) Loss: 0.3445, Acc: 0.8756\n",
            "Epoch 67 / 200 (train) Loss: 0.1984, Acc: 0.9448, (val) Loss: 0.3429, Acc: 0.8756\n",
            "Epoch 68 / 200 (train) Loss: 0.1958, Acc: 0.9465, (val) Loss: 0.3423, Acc: 0.8774\n",
            "Epoch 69 / 200 (train) Loss: 0.1937, Acc: 0.9472, (val) Loss: 0.3425, Acc: 0.8783\n",
            "Epoch 70 / 200 (train) Loss: 0.1913, Acc: 0.9480, (val) Loss: 0.3418, Acc: 0.8783\n",
            "Epoch 71 / 200 (train) Loss: 0.1886, Acc: 0.9492, (val) Loss: 0.3398, Acc: 0.8792\n",
            "Epoch 72 / 200 (train) Loss: 0.1866, Acc: 0.9506, (val) Loss: 0.3389, Acc: 0.8801\n",
            "Epoch 73 / 200 (train) Loss: 0.1839, Acc: 0.9512, (val) Loss: 0.3381, Acc: 0.8810\n",
            "Epoch 74 / 200 (train) Loss: 0.1819, Acc: 0.9522, (val) Loss: 0.3378, Acc: 0.8774\n",
            "Epoch 75 / 200 (train) Loss: 0.1799, Acc: 0.9527, (val) Loss: 0.3379, Acc: 0.8774\n",
            "Epoch 76 / 200 (train) Loss: 0.1772, Acc: 0.9539, (val) Loss: 0.3369, Acc: 0.8783\n",
            "Epoch 77 / 200 (train) Loss: 0.1754, Acc: 0.9541, (val) Loss: 0.3355, Acc: 0.8810\n",
            "Epoch 78 / 200 (train) Loss: 0.1731, Acc: 0.9558, (val) Loss: 0.3350, Acc: 0.8828\n",
            "Epoch 79 / 200 (train) Loss: 0.1712, Acc: 0.9563, (val) Loss: 0.3355, Acc: 0.8828\n",
            "Epoch 80 / 200 (train) Loss: 0.1690, Acc: 0.9570, (val) Loss: 0.3362, Acc: 0.8828\n",
            "Epoch 81 / 200 (train) Loss: 0.1673, Acc: 0.9572, (val) Loss: 0.3360, Acc: 0.8837\n",
            "Epoch 82 / 200 (train) Loss: 0.1659, Acc: 0.9577, (val) Loss: 0.3347, Acc: 0.8856\n",
            "Epoch 83 / 200 (train) Loss: 0.1629, Acc: 0.9592, (val) Loss: 0.3337, Acc: 0.8856\n",
            "Epoch 84 / 200 (train) Loss: 0.1609, Acc: 0.9597, (val) Loss: 0.3335, Acc: 0.8865\n",
            "Epoch 85 / 200 (train) Loss: 0.1589, Acc: 0.9613, (val) Loss: 0.3334, Acc: 0.8856\n",
            "Epoch 86 / 200 (train) Loss: 0.1570, Acc: 0.9627, (val) Loss: 0.3334, Acc: 0.8874\n",
            "Epoch 87 / 200 (train) Loss: 0.1560, Acc: 0.9618, (val) Loss: 0.3329, Acc: 0.8901\n",
            "Epoch 88 / 200 (train) Loss: 0.1535, Acc: 0.9631, (val) Loss: 0.3324, Acc: 0.8892\n",
            "Epoch 89 / 200 (train) Loss: 0.1518, Acc: 0.9643, (val) Loss: 0.3325, Acc: 0.8892\n",
            "Epoch 90 / 200 (train) Loss: 0.1506, Acc: 0.9637, (val) Loss: 0.3316, Acc: 0.8892\n",
            "Epoch 91 / 200 (train) Loss: 0.1486, Acc: 0.9648, (val) Loss: 0.3305, Acc: 0.8901\n",
            "Epoch 92 / 200 (train) Loss: 0.1464, Acc: 0.9657, (val) Loss: 0.3303, Acc: 0.8901\n",
            "Epoch 93 / 200 (train) Loss: 0.1450, Acc: 0.9660, (val) Loss: 0.3299, Acc: 0.8910\n",
            "Epoch 94 / 200 (train) Loss: 0.1433, Acc: 0.9672, (val) Loss: 0.3297, Acc: 0.8901\n",
            "Epoch 95 / 200 (train) Loss: 0.1419, Acc: 0.9675, (val) Loss: 0.3305, Acc: 0.8901\n",
            "Epoch 96 / 200 (train) Loss: 0.1403, Acc: 0.9681, (val) Loss: 0.3295, Acc: 0.8901\n",
            "Epoch 97 / 200 (train) Loss: 0.1384, Acc: 0.9689, (val) Loss: 0.3298, Acc: 0.8910\n",
            "Epoch 98 / 200 (train) Loss: 0.1372, Acc: 0.9693, (val) Loss: 0.3293, Acc: 0.8910\n",
            "Epoch 99 / 200 (train) Loss: 0.1357, Acc: 0.9696, (val) Loss: 0.3287, Acc: 0.8901\n",
            "Epoch 100 / 200 (train) Loss: 0.1346, Acc: 0.9700, (val) Loss: 0.3289, Acc: 0.8901\n",
            "Epoch 101 / 200 (train) Loss: 0.1328, Acc: 0.9708, (val) Loss: 0.3283, Acc: 0.8892\n",
            "Epoch 102 / 200 (train) Loss: 0.1320, Acc: 0.9710, (val) Loss: 0.3286, Acc: 0.8928\n",
            "Epoch 103 / 200 (train) Loss: 0.1301, Acc: 0.9718, (val) Loss: 0.3290, Acc: 0.8928\n",
            "Epoch 104 / 200 (train) Loss: 0.1298, Acc: 0.9726, (val) Loss: 0.3287, Acc: 0.8910\n",
            "Epoch 105 / 200 (train) Loss: 0.1279, Acc: 0.9734, (val) Loss: 0.3279, Acc: 0.8901\n",
            "Epoch 106 / 200 (train) Loss: 0.1258, Acc: 0.9741, (val) Loss: 0.3274, Acc: 0.8919\n",
            "Epoch 107 / 200 (train) Loss: 0.1253, Acc: 0.9730, (val) Loss: 0.3274, Acc: 0.8919\n",
            "Epoch 108 / 200 (train) Loss: 0.1239, Acc: 0.9746, (val) Loss: 0.3283, Acc: 0.8928\n",
            "Epoch 109 / 200 (train) Loss: 0.1229, Acc: 0.9743, (val) Loss: 0.3279, Acc: 0.8919\n",
            "Epoch 110 / 200 (train) Loss: 0.1216, Acc: 0.9744, (val) Loss: 0.3289, Acc: 0.8919\n",
            "Epoch 111 / 200 (train) Loss: 0.1209, Acc: 0.9749, (val) Loss: 0.3285, Acc: 0.8919\n",
            "Epoch 112 / 200 (train) Loss: 0.1195, Acc: 0.9752, (val) Loss: 0.3280, Acc: 0.8955\n",
            "Epoch 113 / 200 (train) Loss: 0.1179, Acc: 0.9764, (val) Loss: 0.3266, Acc: 0.8910\n",
            "Epoch 114 / 200 (train) Loss: 0.1176, Acc: 0.9761, (val) Loss: 0.3274, Acc: 0.8910\n",
            "Epoch 115 / 200 (train) Loss: 0.1160, Acc: 0.9765, (val) Loss: 0.3279, Acc: 0.8919\n",
            "Epoch 116 / 200 (train) Loss: 0.1150, Acc: 0.9773, (val) Loss: 0.3275, Acc: 0.8910\n",
            "Epoch 117 / 200 (train) Loss: 0.1144, Acc: 0.9776, (val) Loss: 0.3275, Acc: 0.8919\n",
            "Epoch 118 / 200 (train) Loss: 0.1137, Acc: 0.9782, (val) Loss: 0.3278, Acc: 0.8901\n",
            "Epoch 119 / 200 (train) Loss: 0.1123, Acc: 0.9788, (val) Loss: 0.3286, Acc: 0.8901\n",
            "Epoch 120 / 200 (train) Loss: 0.1111, Acc: 0.9789, (val) Loss: 0.3280, Acc: 0.8919\n",
            "Epoch 121 / 200 (train) Loss: 0.1102, Acc: 0.9798, (val) Loss: 0.3281, Acc: 0.8901\n",
            "Epoch 122 / 200 (train) Loss: 0.1094, Acc: 0.9801, (val) Loss: 0.3282, Acc: 0.8883\n",
            "Epoch 123 / 200 (train) Loss: 0.1086, Acc: 0.9815, (val) Loss: 0.3270, Acc: 0.8910\n",
            "Epoch 124 / 200 (train) Loss: 0.1076, Acc: 0.9802, (val) Loss: 0.3278, Acc: 0.8910\n",
            "Epoch 125 / 200 (train) Loss: 0.1069, Acc: 0.9810, (val) Loss: 0.3277, Acc: 0.8910\n",
            "Epoch 126 / 200 (train) Loss: 0.1066, Acc: 0.9805, (val) Loss: 0.3273, Acc: 0.8910\n",
            "Epoch 127 / 200 (train) Loss: 0.1057, Acc: 0.9818, (val) Loss: 0.3273, Acc: 0.8910\n",
            "Epoch 128 / 200 (train) Loss: 0.1053, Acc: 0.9814, (val) Loss: 0.3270, Acc: 0.8910\n",
            "Epoch 129 / 200 (train) Loss: 0.1044, Acc: 0.9815, (val) Loss: 0.3274, Acc: 0.8919\n",
            "Epoch 130 / 200 (train) Loss: 0.1033, Acc: 0.9821, (val) Loss: 0.3273, Acc: 0.8919\n",
            "Epoch 131 / 200 (train) Loss: 0.1025, Acc: 0.9831, (val) Loss: 0.3277, Acc: 0.8919\n",
            "Epoch 132 / 200 (train) Loss: 0.1019, Acc: 0.9823, (val) Loss: 0.3269, Acc: 0.8919\n",
            "Epoch 133 / 200 (train) Loss: 0.1013, Acc: 0.9821, (val) Loss: 0.3276, Acc: 0.8919\n",
            "Epoch 134 / 200 (train) Loss: 0.1005, Acc: 0.9825, (val) Loss: 0.3276, Acc: 0.8919\n",
            "Epoch 135 / 200 (train) Loss: 0.0997, Acc: 0.9833, (val) Loss: 0.3274, Acc: 0.8919\n",
            "Epoch 136 / 200 (train) Loss: 0.1002, Acc: 0.9826, (val) Loss: 0.3276, Acc: 0.8910\n",
            "Epoch 137 / 200 (train) Loss: 0.0991, Acc: 0.9826, (val) Loss: 0.3278, Acc: 0.8910\n",
            "Epoch 138 / 200 (train) Loss: 0.0985, Acc: 0.9838, (val) Loss: 0.3274, Acc: 0.8928\n",
            "Epoch 139 / 200 (train) Loss: 0.0978, Acc: 0.9842, (val) Loss: 0.3276, Acc: 0.8928\n",
            "Epoch 140 / 200 (train) Loss: 0.0977, Acc: 0.9833, (val) Loss: 0.3280, Acc: 0.8928\n",
            "Epoch 141 / 200 (train) Loss: 0.0972, Acc: 0.9839, (val) Loss: 0.3285, Acc: 0.8928\n",
            "Epoch 142 / 200 (train) Loss: 0.0961, Acc: 0.9840, (val) Loss: 0.3292, Acc: 0.8928\n",
            "Epoch 143 / 200 (train) Loss: 0.0958, Acc: 0.9841, (val) Loss: 0.3282, Acc: 0.8928\n",
            "Epoch 144 / 200 (train) Loss: 0.0952, Acc: 0.9835, (val) Loss: 0.3281, Acc: 0.8928\n",
            "Epoch 145 / 200 (train) Loss: 0.0951, Acc: 0.9846, (val) Loss: 0.3276, Acc: 0.8928\n",
            "Epoch 146 / 200 (train) Loss: 0.0954, Acc: 0.9839, (val) Loss: 0.3277, Acc: 0.8928\n",
            "Epoch 147 / 200 (train) Loss: 0.0937, Acc: 0.9851, (val) Loss: 0.3273, Acc: 0.8928\n",
            "Epoch 148 / 200 (train) Loss: 0.0937, Acc: 0.9853, (val) Loss: 0.3269, Acc: 0.8919\n",
            "Epoch 149 / 200 (train) Loss: 0.0935, Acc: 0.9851, (val) Loss: 0.3265, Acc: 0.8928\n",
            "Epoch 150 / 200 (train) Loss: 0.0932, Acc: 0.9858, (val) Loss: 0.3274, Acc: 0.8919\n",
            "Epoch 151 / 200 (train) Loss: 0.0932, Acc: 0.9852, (val) Loss: 0.3276, Acc: 0.8919\n",
            "Epoch 152 / 200 (train) Loss: 0.0920, Acc: 0.9847, (val) Loss: 0.3279, Acc: 0.8928\n",
            "Epoch 153 / 200 (train) Loss: 0.0916, Acc: 0.9855, (val) Loss: 0.3277, Acc: 0.8937\n",
            "Epoch 154 / 200 (train) Loss: 0.0912, Acc: 0.9860, (val) Loss: 0.3276, Acc: 0.8937\n",
            "Epoch 155 / 200 (train) Loss: 0.0909, Acc: 0.9859, (val) Loss: 0.3272, Acc: 0.8937\n",
            "Epoch 156 / 200 (train) Loss: 0.0907, Acc: 0.9860, (val) Loss: 0.3269, Acc: 0.8937\n",
            "Epoch 157 / 200 (train) Loss: 0.0905, Acc: 0.9866, (val) Loss: 0.3275, Acc: 0.8928\n",
            "Epoch 158 / 200 (train) Loss: 0.0902, Acc: 0.9856, (val) Loss: 0.3278, Acc: 0.8919\n",
            "Epoch 159 / 200 (train) Loss: 0.0900, Acc: 0.9857, (val) Loss: 0.3281, Acc: 0.8928\n",
            "Epoch 160 / 200 (train) Loss: 0.0897, Acc: 0.9873, (val) Loss: 0.3273, Acc: 0.8937\n",
            "Epoch 161 / 200 (train) Loss: 0.0891, Acc: 0.9868, (val) Loss: 0.3275, Acc: 0.8928\n",
            "Epoch 162 / 200 (train) Loss: 0.0896, Acc: 0.9868, (val) Loss: 0.3277, Acc: 0.8928\n",
            "Epoch 163 / 200 (train) Loss: 0.0891, Acc: 0.9864, (val) Loss: 0.3283, Acc: 0.8919\n",
            "Epoch 164 / 200 (train) Loss: 0.0890, Acc: 0.9861, (val) Loss: 0.3282, Acc: 0.8928\n",
            "Epoch 165 / 200 (train) Loss: 0.0886, Acc: 0.9871, (val) Loss: 0.3281, Acc: 0.8928\n",
            "Epoch 166 / 200 (train) Loss: 0.0887, Acc: 0.9873, (val) Loss: 0.3280, Acc: 0.8928\n",
            "Epoch 167 / 200 (train) Loss: 0.0880, Acc: 0.9871, (val) Loss: 0.3282, Acc: 0.8919\n",
            "Epoch 168 / 200 (train) Loss: 0.0881, Acc: 0.9869, (val) Loss: 0.3277, Acc: 0.8928\n",
            "Epoch 169 / 200 (train) Loss: 0.0881, Acc: 0.9875, (val) Loss: 0.3278, Acc: 0.8928\n",
            "Epoch 170 / 200 (train) Loss: 0.0878, Acc: 0.9875, (val) Loss: 0.3278, Acc: 0.8928\n",
            "Epoch 171 / 200 (train) Loss: 0.0879, Acc: 0.9869, (val) Loss: 0.3282, Acc: 0.8928\n",
            "Epoch 172 / 200 (train) Loss: 0.0872, Acc: 0.9873, (val) Loss: 0.3282, Acc: 0.8928\n",
            "Epoch 173 / 200 (train) Loss: 0.0882, Acc: 0.9871, (val) Loss: 0.3277, Acc: 0.8928\n",
            "Epoch 174 / 200 (train) Loss: 0.0873, Acc: 0.9880, (val) Loss: 0.3280, Acc: 0.8928\n",
            "Epoch 175 / 200 (train) Loss: 0.0870, Acc: 0.9877, (val) Loss: 0.3275, Acc: 0.8928\n",
            "Epoch 176 / 200 (train) Loss: 0.0877, Acc: 0.9868, (val) Loss: 0.3274, Acc: 0.8928\n",
            "Epoch 177 / 200 (train) Loss: 0.0867, Acc: 0.9874, (val) Loss: 0.3275, Acc: 0.8937\n",
            "Epoch 178 / 200 (train) Loss: 0.0868, Acc: 0.9875, (val) Loss: 0.3276, Acc: 0.8946\n",
            "Epoch 179 / 200 (train) Loss: 0.0865, Acc: 0.9883, (val) Loss: 0.3280, Acc: 0.8928\n",
            "Epoch 180 / 200 (train) Loss: 0.0866, Acc: 0.9871, (val) Loss: 0.3277, Acc: 0.8928\n",
            "Epoch 181 / 200 (train) Loss: 0.0863, Acc: 0.9875, (val) Loss: 0.3281, Acc: 0.8919\n",
            "Epoch 182 / 200 (train) Loss: 0.0866, Acc: 0.9866, (val) Loss: 0.3277, Acc: 0.8937\n",
            "Epoch 183 / 200 (train) Loss: 0.0862, Acc: 0.9880, (val) Loss: 0.3277, Acc: 0.8937\n",
            "Epoch 184 / 200 (train) Loss: 0.0865, Acc: 0.9876, (val) Loss: 0.3276, Acc: 0.8937\n",
            "Epoch 185 / 200 (train) Loss: 0.0859, Acc: 0.9882, (val) Loss: 0.3279, Acc: 0.8937\n",
            "Epoch 186 / 200 (train) Loss: 0.0860, Acc: 0.9881, (val) Loss: 0.3281, Acc: 0.8937\n",
            "Epoch 187 / 200 (train) Loss: 0.0862, Acc: 0.9882, (val) Loss: 0.3288, Acc: 0.8919\n",
            "Epoch 188 / 200 (train) Loss: 0.0862, Acc: 0.9873, (val) Loss: 0.3282, Acc: 0.8919\n",
            "Epoch 189 / 200 (train) Loss: 0.0860, Acc: 0.9877, (val) Loss: 0.3281, Acc: 0.8928\n",
            "Epoch 190 / 200 (train) Loss: 0.0865, Acc: 0.9877, (val) Loss: 0.3280, Acc: 0.8937\n",
            "Epoch 191 / 200 (train) Loss: 0.0858, Acc: 0.9876, (val) Loss: 0.3281, Acc: 0.8937\n",
            "Epoch 192 / 200 (train) Loss: 0.0863, Acc: 0.9876, (val) Loss: 0.3276, Acc: 0.8937\n",
            "Epoch 193 / 200 (train) Loss: 0.0864, Acc: 0.9877, (val) Loss: 0.3275, Acc: 0.8937\n",
            "Epoch 194 / 200 (train) Loss: 0.0860, Acc: 0.9883, (val) Loss: 0.3271, Acc: 0.8946\n",
            "Epoch 195 / 200 (train) Loss: 0.0861, Acc: 0.9872, (val) Loss: 0.3278, Acc: 0.8928\n",
            "Epoch 196 / 200 (train) Loss: 0.0857, Acc: 0.9883, (val) Loss: 0.3280, Acc: 0.8919\n",
            "Epoch 197 / 200 (train) Loss: 0.0858, Acc: 0.9876, (val) Loss: 0.3279, Acc: 0.8928\n",
            "Epoch 198 / 200 (train) Loss: 0.0858, Acc: 0.9877, (val) Loss: 0.3279, Acc: 0.8919\n",
            "Epoch 199 / 200 (train) Loss: 0.0856, Acc: 0.9882, (val) Loss: 0.3279, Acc: 0.8928\n",
            "Epoch 200 / 200 (train) Loss: 0.0859, Acc: 0.9883, (val) Loss: 0.3282, Acc: 0.8919\n"
          ]
        }
      ]
    }
  ]
}