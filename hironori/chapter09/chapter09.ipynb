{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOAIgnL+Aj7mHpj+GKVuJ0Z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zUZbe2T3wDZh","executionInfo":{"status":"ok","timestamp":1687750252908,"user_tz":-540,"elapsed":18188,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}},"outputId":"3b18aa1f-1cf6-4fdb-9312-ff3f91866d45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["%matplotlib inline\n","import torch\n","import numpy as np"],"metadata":{"id":"KSYSxnsKwMHR","executionInfo":{"status":"ok","timestamp":1687750329919,"user_tz":-540,"elapsed":6070,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["knock80"],"metadata":{"id":"v3C3gh3-wNDl"}},{"cell_type":"code","source":["import pandas as pd\n","import re\n","\n","def preprc(data):\n","    x = []\n","    y = []\n","    label = {\"b\":0, \"e\":1, \"t\":2, \"m\":3} #ビジネス:0, エンターテインメント:1, 科学技術:2, 健康:3\n","    for l in data:\n","        d = l.split(\"\\t\")\n","        xd = [i.rstrip(\"\\n\").strip(\":'$%?,.()!;\").strip('\"') for i in re.sub(\"[0-9]+\", \"0\", d[1]).lower().split(\" \") if i != \"\" and i != \"...\\n\"]\n","        x.append(xd)\n","        y.append(label[d[0]])\n","    return x, y\n","\n","train = []\n","with open('/content/drive/MyDrive/train.txt', encoding='utf-8') as f:\n","  for l in f:\n","    train.append(l)\n","X_train, Y_train = preprc(train)"],"metadata":{"id":"wgAJg-McwUaD","executionInfo":{"status":"ok","timestamp":1687755789597,"user_tz":-540,"elapsed":306,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}}},"execution_count":56,"outputs":[]},{"cell_type":"code","source":["def cwi(ws, wid):\n","  '''\n","  単語のリストとid番号の辞書を受け取り、id番号のリストを返す\n","  '''\n","  ids = [wid.get(w, 0) for w in ws]\n","  return ids\n","\n","w_cnt = {}\n","for t in X_train:\n","  for w in t:\n","    w_cnt[w] = w_cnt.get(w, 0) + 1\n","w_cnt_sorted = sorted(w_cnt.items(), key=lambda x: x[1], reverse=True)\n","w_id = {}\n","for i, w in enumerate(w_cnt_sorted, 1):\n","  if w[1] < 2:\n","    break\n","  w_id[w[0]] = i"],"metadata":{"id":"OI-vVAOb1Rnr","executionInfo":{"status":"ok","timestamp":1687755791783,"user_tz":-540,"elapsed":415,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}}},"execution_count":57,"outputs":[]},{"cell_type":"markdown","source":["knock81"],"metadata":{"id":"2FbeE4Ys6uvE"}},{"cell_type":"code","source":["Xid_train = [cwi(t, w_id) for t in X_train]"],"metadata":{"id":"dryawPj5AgZa","executionInfo":{"status":"ok","timestamp":1687760897262,"user_tz":-540,"elapsed":311,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["import torch.nn as nn\n","from torch.utils.data import Dataset\n","\n","class TextDataset(Dataset):\n","  def __init__(self, X, y):\n","    self.X = X\n","    self.y = y\n","\n","  def __len__(self):\n","    return len(self.X)\n","\n","  def __getitem__(self, idx):\n","    X_list = [x for x in self.X[idx]]\n","    inputs = torch.tensor(X_list)\n","    label = torch.tensor(self.y[idx])\n","    return inputs, label\n","\n","class RNN(nn.Module):\n","  def __init__(self, vocab_size, emb_dim=300, hidden_size=50, output_size=4):\n","    super().__init__()\n","    self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n","    self.rnn = nn.RNN(input_size=emb_dim, hidden_size=hidden_size, num_layers=1, nonlinearity=\"tanh\", bias=True)\n","    self.fc = nn.Linear(in_features=hidden_size, out_features=output_size, bias=True)\n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x, h_0=None):\n","    x = self.emb(x)\n","    x, h_t = self.rnn(x, h_0)\n","    x = self.fc(x)\n","    x = self.softmax(x)\n","    return x\n","\n","model = RNN(len(w_id))\n","ds = TextDataset(Xid_train, Y_train)\n","\n","for i in range(10):\n","  X = ds[i][0]\n","  X.unsqueeze(0)\n","  print(model(x=X)[-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d_8gUFxc6sqU","executionInfo":{"status":"ok","timestamp":1687759173525,"user_tz":-540,"elapsed":302,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}},"outputId":"4c2e2238-b18b-4ceb-9167-1926c3bc3391"},"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([0.3437, 0.1723, 0.2938, 0.1902], grad_fn=<SelectBackward0>)\n","tensor([0.2344, 0.2446, 0.1978, 0.3232], grad_fn=<SelectBackward0>)\n","tensor([0.2510, 0.1975, 0.3507, 0.2007], grad_fn=<SelectBackward0>)\n","tensor([0.1803, 0.4115, 0.2490, 0.1592], grad_fn=<SelectBackward0>)\n","tensor([0.1972, 0.2187, 0.4696, 0.1145], grad_fn=<SelectBackward0>)\n","tensor([0.3315, 0.2255, 0.2565, 0.1865], grad_fn=<SelectBackward0>)\n","tensor([0.3176, 0.1294, 0.1767, 0.3763], grad_fn=<SelectBackward0>)\n","tensor([0.1634, 0.3666, 0.3025, 0.1676], grad_fn=<SelectBackward0>)\n","tensor([0.1535, 0.2949, 0.4009, 0.1507], grad_fn=<SelectBackward0>)\n","tensor([0.3186, 0.2656, 0.1583, 0.2576], grad_fn=<SelectBackward0>)\n"]}]},{"cell_type":"markdown","source":["knock82"],"metadata":{"id":"nOcitx72Sfo-"}},{"cell_type":"code","source":["valid = []\n","test = []\n","with open('/content/drive/MyDrive/valid.txt', encoding='utf-8') as f:\n","  for l in f:\n","    valid.append(l)\n","with open('/content/drive/MyDrive/test.txt', encoding='utf-8') as f:\n","  for l in f:\n","    test.append(l)\n","X_valid, Y_valid = preprc(valid)\n","X_test, Y_test = preprc(test)\n","Xid_valid = [cwi(t, w_id) for t in X_valid]\n","Xid_test = [cwi(t, w_id) for t in X_test]"],"metadata":{"id":"5PURy-O1Ui5a","executionInfo":{"status":"ok","timestamp":1687760902105,"user_tz":-540,"elapsed":1000,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}}},"execution_count":98,"outputs":[]},{"cell_type":"code","source":["import os\n","import random\n","import time\n","import matplotlib.pyplot as plt\n","from torch.utils.data import DataLoader\n","from tqdm import tqdm\n","\n","def seed_everything(seed=42, use_torch=False):\n","  random.seed(seed)\n","  os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","  np.random.seed(seed)\n","  if use_torch:\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)\n","    torch.backends.cudnn.deterministic = True\n","\n","seed_everything(use_torch=True)\n","\n","def train_fn(model, loader, optimizer, criterion, BATCHSIZE, HIDDEN_SIZE) -> float:\n","  model.train()\n","  train_running_loss = 0.0\n","  for dataloader_x, dataloader_y in loader:\n","    optimizer.zero_grad()\n","    dataloader_y_pred_prob = model(x=dataloader_x)\n","    print(dataloader_y_pred_prob)\n","    loss = criterion(dataloader_y_pred_prob, dataloader_y)\n","    loss.backward()\n","    optimizer.step()\n","    train_running_loss += loss.item() / len(loader)\n","  return train_running_loss\n","\n","def calculate_loss_and_accuracy(model, dataset, device=None, criterion=None):\n","  model.eval()\n","  dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n","\n","  loss = 0.0\n","  total = 0\n","  correct = 0\n","\n","  with torch.no_grad():\n","    for dataloader_x, dataloader_y in dataloader:\n","      outputs = model(dataloader_x)\n","      loss += criterion(outputs, dataloader_y).item()\n","      pred = torch.argmax(outputs, dim=-1)\n","      total += len(dataloader_x)\n","      correct += (pred == dataloader_y).sum().item()\n","\n","  return loss / len(dataset), correct / total\n","\n","def padding(id_list, max_len):\n","  if len(id_list) > max_len:\n","    id_list = id_list[:max_len]\n","  else:\n","    pad_num = max_len - len(id_list)\n","    for _ in range(pad_num):\n","      id_list.append(0)\n","  return id_list\n","\n","def make_graph(value_dict: dict, value_name: str, bn: int, method: str):\n","  for phase in [\"train\", \"test\"]:\n","    plt.plot(value_dict[phase], label=phase)\n","  plt.xlabel(\"epoch\")\n","  plt.ylabel(value_name)\n","  plt.title(f\"{value_name} per epoch at bn{bn}\")\n","  plt.legend()\n","  plt.savefig(f\"{method}_{value_name}_bn{bn}.png\")\n","  plt.close()\n","\n","\n","start = time.time()\n","\n","max_len = 10\n","Xid_train = [padding(i, max_len) for i in Xid_train]\n","Xid_test = [padding(i, max_len) for i in Xid_test]\n","\n","N_LETTERS = len(w_id) + 1\n","EMB_SIZE = 300\n","HIDDEN_SIZE = 50\n","N_CATEGORIES = 4\n","\n","model = RNN(vocab_size=N_LETTERS, emb_dim=EMB_SIZE, hidden_size=HIDDEN_SIZE, output_size=N_CATEGORIES)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n","\n","dataset_train = TextDataset(Xid_train, Y_train)\n","dataset_test = TextDataset(Xid_test, Y_test)\n","\n","BATCHSIZE = 1\n","dataloader_train = DataLoader(dataset_train, batch_size=BATCHSIZE, shuffle=False, drop_last=True)\n","\n","train_losses = []\n","train_accs = []\n","test_losses = []\n","test_accs = []\n","\n","device = (torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\"))\n","\n","EPOCH = 10\n","for epoch in tqdm(range(EPOCH)):\n","\n","  train_running_loss = train_fn(model, dataloader_train, optimizer, criterion, BATCHSIZE, HIDDEN_SIZE)\n","  print(train_running_loss)\n","\n","  train_loss, train_acc = calculate_loss_and_accuracy(model, dataset_train, device, criterion)\n","  test_loss, test_acc = calculate_loss_and_accuracy(model, dataset_test, device, criterion)\n","\n","  train_losses.append(train_loss)\n","  train_accs.append(train_acc)\n","\n","  test_losses.append(test_loss)\n","  test_accs.append(test_acc)\n","\n","  if epoch % 20 == 0:\n","      torch.save(model.state_dict(), f\"82_model_epoch{epoch}.pth\")\n","      torch.save(\n","          optimizer.state_dict(),\n","          f\"82_optimizer_epoch{epoch}.pth\",\n","      )\n","\n","losses = {\"train\": train_losses, \"test\": test_losses}\n","\n","accs = {\"train\": train_accs, \"test\": test_accs}\n","\n","make_graph(losses, \"losses\", bn=BATCHSIZE, method=\"rnn\")\n","make_graph(accs, \"accs\", bn=BATCHSIZE, method=\"rnn\")\n","\n","print(f\"train_acc: {train_acc}\")\n","print(f\"test_acc: {test_acc}\")\n","\n","elapsed_time = time.time() - start\n","print(elapsed_time)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":594},"id":"rfCkdea2ShKE","executionInfo":{"status":"error","timestamp":1687762694272,"user_tz":-540,"elapsed":280,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}},"outputId":"9776694b-0121-45c4-9fb7-08381222a959"},"execution_count":110,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor([[[0.1272, 0.1184, 0.0731, 0.0681],\n","         [0.0858, 0.0557, 0.0519, 0.1484],\n","         [0.0519, 0.0915, 0.1495, 0.1712],\n","         [0.1978, 0.1605, 0.1368, 0.0493],\n","         [0.1034, 0.0379, 0.1144, 0.0885],\n","         [0.0334, 0.0947, 0.1129, 0.0950],\n","         [0.1274, 0.1390, 0.0488, 0.1111],\n","         [0.0333, 0.0990, 0.1015, 0.1157],\n","         [0.0750, 0.0987, 0.1766, 0.0726],\n","         [0.1648, 0.1046, 0.0344, 0.0800]]], grad_fn=<SoftmaxBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-110-909319f2090a>\u001b[0m in \u001b[0;36m<cell line: 100>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m   \u001b[0mtrain_running_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCHSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_running_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-110-909319f2090a>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, loader, optimizer, criterion, BATCHSIZE, HIDDEN_SIZE)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mdataloader_y_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_y_pred_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_y_pred_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3029\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3031\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected target size [1, 4], got [1]"]}]},{"cell_type":"markdown","source":["knock83"],"metadata":{"id":"zwrFfWTeZYE5"}},{"cell_type":"code","source":["def train_fn(model, loader, device, optimizer, criterion, BATCHSIZE, HIDDEN_SIZE) -> float:\n","    model.train()\n","    train_running_loss = 0.0\n","\n","    for dataloader_x, dataloader_y in loader:\n","        dataloader_x.to(device)\n","        dataloader_y.to(device)\n","        optimizer.zero_grad()\n","\n","        dataloader_y_pred_prob = model(x=dataloader_x, h_0=torch.zeros(1 * 1, BATCHSIZE, HIDDEN_SIZE))\n","\n","        loss = criterion(dataloader_y_pred_prob, dataloader_y)\n","        loss.backward()\n","        optimizer.step()\n","\n","        train_running_loss += loss.item() / len(loader)\n","\n","    return train_running_loss\n","\n","N_LETTERS = len(w_id) + 1\n","EMB_SIZE = 300\n","HIDDEN_SIZE = 50\n","N_CATEGORIES = 4\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","model = RNN(vocab_size=N_LETTERS, emb_dim=EMB_SIZE, hidden_size=HIDDEN_SIZE, output_size=N_CATEGORIES).to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n","\n","BATCHSIZE = 32\n","dataloader_train = DataLoader(dataset_train, batch_size=BATCHSIZE, shuffle=True, drop_last=True)\n","\n","train_losses = []\n","train_accs = []\n","test_losses = []\n","test_accs = []\n","\n","EPOCH = 10\n","for epoch in tqdm(range(EPOCH)):\n","  train_running_loss = train_fn(\n","    model,\n","    dataloader_train,\n","    device,\n","    optimizer,\n","    criterion,\n","    BATCHSIZE,\n","    HIDDEN_SIZE,\n","  )\n","  print(train_running_loss)\n","\n","  train_loss, train_acc = calculate_loss_and_accuracy(model, dataset_train, device, criterion)\n","  test_loss, test_acc = calculate_loss_and_accuracy(model, dataset_test, device, criterion)\n","\n","  train_losses.append(train_loss)\n","  train_accs.append(train_acc)\n","\n","  test_losses.append(test_loss)\n","  test_accs.append(test_acc)\n","\n","  if epoch % 20 == 0:\n","      torch.save(model.state_dict(), f\"83_model_epoch{epoch}.pth\")\n","      torch.save(optimizer.state_dict(), f\"83_optimizer_epoch{epoch}.pth\")\n","\n","losses = {\"train\": train_losses, \"test\": test_losses}\n","\n","accs = {\"train\": train_accs, \"test\": test_accs}\n","\n","make_graph(losses, \"losses\", method=\"rnn\")\n","make_graph(accs, \"accs\", method=\"rnn\")\n","\n","print(f\"train_acc: {train_acc}\")\n","print(f\"test_acc: {test_acc}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":403},"id":"1yXds23PZaYL","executionInfo":{"status":"error","timestamp":1687763774052,"user_tz":-540,"elapsed":307,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}},"outputId":"e0f73c9b-a55f-4af1-a6b9-023f225799c0"},"execution_count":113,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/10 [00:00<?, ?it/s]\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-113-a0cdb45fe5e4>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mEPOCH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m   train_running_loss = train_fn(\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-113-a0cdb45fe5e4>\u001b[0m in \u001b[0;36mtrain_fn\u001b[0;34m(model, loader, device, optimizer, criterion, BATCHSIZE, HIDDEN_SIZE)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mdataloader_y_pred_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataloader_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBATCHSIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHIDDEN_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_y_pred_prob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-90-1fb99e386a4a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, h_0)\u001b[0m\n\u001b[1;32m     26\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mhx\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RNN_TANH'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'RNN_RELU'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[0;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mexpected_hidden_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expected_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_hidden_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpermute_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpermutation\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mcheck_hidden_size\u001b[0;34m(self, hx, expected_hidden_size, msg)\u001b[0m\n\u001b[1;32m    237\u001b[0m                           msg: str = 'Expected hidden size {}, got {}') -> None:\n\u001b[1;32m    238\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_hidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_weights_have_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Expected hidden size (1, 10, 50), got [1, 32, 50]"]}]},{"cell_type":"markdown","source":["knock84"],"metadata":{"id":"BWeyOlYxf62W"}},{"cell_type":"code","source":["from gensim.models import KeyedVectors\n","model_GN = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/GoogleNews-vectors-negative300.bin.gz', binary=True)"],"metadata":{"id":"js4rEgOHlcl_","executionInfo":{"status":"ok","timestamp":1687764306257,"user_tz":-540,"elapsed":77150,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}}},"execution_count":121,"outputs":[]},{"cell_type":"code","source":["class RNN(nn.Module):\n","  def __init__(self, vocab_size, emb_dim, hidden_size, output_size, word_id_dict):\n","    super().__init__()\n","    model = model_GN\n","    weight = torch.zeros(len(word_id_dict) + 1, 300)\n","    for word, idx in word_id_dict.items():\n","      if word in model.vocab.keys():\n","        weight[idx] = torch.tensor(model[word])\n","\n","    self.emb = nn.Embedding.from_pretrained(weight, padding_idx=0)\n","\n","    self.rnn = nn.RNN(\n","        input_size=emb_dim,\n","        hidden_size=hidden_size,\n","        num_layers=1,\n","        nonlinearity=\"tanh\",\n","        bias=True,\n","        batch_first=True,\n","    )\n","\n","    self.fc = nn.Linear(in_features=hidden_size, out_features=output_size, bias=True)\n","\n","    self.softmax = nn.Softmax(dim=1)\n","\n","  def forward(self, x, h_0=None):\n","    x = self.emb(x)\n","    x, h_t = self.rnn(x, h_0)\n","    x = x[:, -1, :]\n","    x = self.fc(x)\n","    x = self.softmax(x)\n","    return x"],"metadata":{"id":"Thyfby-1k_5J","executionInfo":{"status":"ok","timestamp":1687764417940,"user_tz":-540,"elapsed":285,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}}},"execution_count":124,"outputs":[]},{"cell_type":"code","source":["model = RNN(\n","  vocab_size=N_LETTERS,\n","  emb_dim=EMB_SIZE,\n","  hidden_size=HIDDEN_SIZE,\n","  output_size=N_CATEGORIES,\n","  word_id_dict=w_id,\n",").to(device)\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.05)\n","\n","train_losses = []\n","train_accs = []\n","test_losses = []\n","test_accs = []\n","\n","EPOCH = 10\n","for epoch in tqdm(range(EPOCH)):\n","\n","  train_running_loss = train_fn(\n","    model,\n","    dataloader_train,\n","    device,\n","    optimizer,\n","    criterion,\n","    BATCHSIZE,\n","    HIDDEN_SIZE,\n","  )\n","  print(train_running_loss)\n","\n","  train_loss, train_acc = calculate_loss_and_accuracy(\n","      model, dataset_train, device, criterion\n","  )\n","  test_loss, test_acc = calculate_loss_and_accuracy(\n","      model, dataset_test, device, criterion\n","  )\n","\n","  train_losses.append(train_loss)\n","  train_accs.append(train_acc)\n","\n","  test_losses.append(test_loss)\n","  test_accs.append(test_acc)\n","\n","losses = {\"train\": train_losses, \"test\": test_losses}\n","\n","accs = {\"train\": train_accs, \"test\": test_accs}\n","\n","make_graph(losses, \"losses\", bn=BATCHSIZE, method=\"rnn_pretrain\")\n","make_graph(accs, \"accs\", bn=BATCHSIZE, method=\"rnn_pretrain\")\n","\n","print(f\"train_acc: {train_acc}\")\n","print(f\"test_acc: {test_acc}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":542},"id":"pgW_S9P7f8qo","executionInfo":{"status":"error","timestamp":1687764420718,"user_tz":-540,"elapsed":457,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}},"outputId":"4d630fdf-5866-4200-f002-ee52072e196a"},"execution_count":125,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-125-ce3d19226e5a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = RNN(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_LETTERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHIDDEN_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_CATEGORIES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-124-e9c935fe022b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, emb_dim, hidden_size, output_size, word_id_dict)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_id_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_id_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mvocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;34m\"The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;34m\"Use KeyedVector's .key_to_index dict, .index_to_key list, and methods \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"]}]},{"cell_type":"markdown","source":["knock85"],"metadata":{"id":"KfidxKi4lKvn"}},{"cell_type":"code","source":["model = RNN(\n","  vocab_size=N_LETTERS,\n","  emb_dim=EMB_SIZE,\n","  hidden_size=HIDDEN_SIZE,\n","  output_size=N_CATEGORIES,\n","  word_id_dict=w_id,\n",").to(device)\n","\n","EPOCH = 10\n","for epoch in tqdm(range(EPOCH)):\n","\n","  train_running_loss = train_fn(\n","    model,\n","    dataloader_train,\n","    device,\n","    optimizer,\n","    criterion,\n","    BATCHSIZE,\n","    HIDDEN_SIZE,\n","  )\n","  print(train_running_loss)\n","\n","  train_loss, train_acc = calculate_loss_and_accuracy(\n","    model, dataset_train, device, criterion\n","  )\n","  test_loss, test_acc = calculate_loss_and_accuracy(\n","    model, dataset_test, device, criterion\n","  )\n","\n","  train_losses.append(train_loss)\n","  train_accs.append(train_acc)\n","\n","  test_losses.append(test_loss)\n","  test_accs.append(test_acc)\n","\n","losses = {\"train\": train_losses, \"test\": test_losses}\n","\n","accs = {\"train\": train_accs, \"test\": test_accs}\n","\n","make_graph(losses, \"losses\", bn=BATCHSIZE, method=\"rnn_bidirectional_3layer\")\n","make_graph(accs, \"accs\", bn=BATCHSIZE, method=\"rnn_bidirectional_3layer\")\n","\n","print(f\"train_acc: {train_acc: .4f}\")\n","print(f\"test_acc: {test_acc: .4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":420},"id":"XCl6jrJflMKN","executionInfo":{"status":"error","timestamp":1687764504012,"user_tz":-540,"elapsed":423,"user":{"displayName":"hiironori yamazaki","userId":"00119389574969395519"}},"outputId":"ca7f7547-ff19-47e0-aba7-f258f7038e9d"},"execution_count":128,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-128-f51133350002>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = RNN(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_LETTERS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0memb_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEMB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mHIDDEN_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0moutput_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mN_CATEGORIES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-124-e9c935fe022b>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, emb_dim, hidden_size, output_size, word_id_dict)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_id_dict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_id_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m       \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mvocab\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;34m\"The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             \u001b[0;34m\"Use KeyedVector's .key_to_index dict, .index_to_key list, and methods \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: The vocab attribute was removed from KeyedVector in Gensim 4.0.0.\nUse KeyedVector's .key_to_index dict, .index_to_key list, and methods .get_vecattr(key, attr) and .set_vecattr(key, attr, new_val) instead.\nSee https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4"]}]}]}