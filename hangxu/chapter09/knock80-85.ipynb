{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNLHH80737V2L9KCVlrstpO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"iac11aMlbohr","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687936549505,"user_tz":-540,"elapsed":88284,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"3e3ecb04-d4f2-4674-956f-31644ec1ee00"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"markdown","source":["**knock80**"],"metadata":{"id":"_4W7uwWRcDdE"}},{"cell_type":"code","source":["##knock50\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","\n","#ファイルを読み込む\n","data = pd.read_csv('drive/MyDrive/chapter09/newsCorpora.csv', sep = '\\t', header = None, names = ['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n","\n","#事例（記事）を抽出する\n","data = data.loc[data['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n","\n","#分割する\n","##shuffle：分割する前dataをランダムにする\n","train, valid_test = train_test_split(data, test_size=0.2, shuffle=True, random_state=123, stratify=data['CATEGORY'])\n","valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])\n","train.reset_index(drop=True, inplace=True)\n","valid.reset_index(drop=True, inplace=True)\n","test.reset_index(drop=True, inplace=True)"],"metadata":{"id":"avSDqu3gcHfY","executionInfo":{"status":"ok","timestamp":1687936625826,"user_tz":-540,"elapsed":4132,"user":{"displayName":"周航旭","userId":"09485546673902671804"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from collections import defaultdict\n","import string\n","\n","#単語の頻度集計\n","d = defaultdict(int) #辞書d\n","table = str.maketrans(string.punctuation, ' '*len(string.punctuation))  #記号をスペースに置換する\n","for text in train['TITLE']:\n","  for word in text.translate(table).split():\n","    d[word]+= 1 #単語の頻度を増やす\n","d = sorted(d.items(), key=lambda x:x[1], reverse=True) #reverse:降順\n","\n","#単語ID辞書の作成\n","word2id = {word: i+ 1 for i, (word, fre) in enumerate(d) if fre> 2}  #出現頻度が2回以上\n","\n","print(f'ID数: {len(set(word2id.values()))}\\n')\n","for key in list(word2id)[:10]:\n","    print(f'{key}: {word2id[key]}') #頻度上位10"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QO4UVO_qe5-1","executionInfo":{"status":"ok","timestamp":1687936635425,"user_tz":-540,"elapsed":322,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"e1b54daf-4ed1-4c22-db67-89e4ede3f62e"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["ID数: 6666\n","\n","to: 1\n","s: 2\n","in: 3\n","on: 4\n","UPDATE: 5\n","as: 6\n","US: 7\n","for: 8\n","of: 9\n","The: 10\n"]}]},{"cell_type":"code","source":["#文章を入力として、その文中の単語を先頭からID化\n","def tokenizer(text, word2id=word2id, unk=0):\n","  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n","  return [word2id.get(word, unk) for word in text.translate(table).split()] #単語を辞書word2idから対応するIDに変換\n","\n","#確認\n","text = train.iloc[1, train.columns.get_loc('TITLE')]\n","print(f'テキスト: {text}')\n","print(f'ID列: {tokenizer(text)}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q2HBlNKnfuOW","executionInfo":{"status":"ok","timestamp":1687936638388,"user_tz":-540,"elapsed":8,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"15426bdf-9748-49ed-dbca-b214f9aa0f04"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["テキスト: FOREX-Dollar rises on US rate speculation after Yellen comments\n","ID列: [55, 59, 161, 4, 7, 234, 3530, 26, 97, 429]\n"]}]},{"cell_type":"markdown","source":["**knock81**"],"metadata":{"id":"6TPabeCkjPaV"}},{"cell_type":"code","source":["#RNNモデルを構築\n","import torch\n","from torch import nn\n","class RNN (nn.Module):\n","  def __init__(self, vocab_size, emb_size, padding_idx, output_size, hidden_size):\n","    super().__init__()\n","    self.hidden_size = hidden_size\n","    self.emb = nn.Embedding(vocab_size, emb_size, padding_idx = padding_idx) #単語の埋め込み\n","    self.rnn = nn.RNN(emb_size, hidden_size, nonlinearity = 'tanh', batch_first = True) #tanh: 双曲線正接関数\n","    self.fc = nn.Linear(hidden_size, output_size) #隠れ層から出力層への線形変換\n","\n","  def forward(self,x): #順伝播の計算\n","    self.batch_size = x.size()[0]\n","    hidden = self.init_hidden(x.device)\n","    emb = self.emb(x) #emb.size()=(batch_size, seq_len, emb_size)\n","    out, hidden = self.rnn(emb, hidden) #out.size()=(batch_size, seq_len, hidden_size)\n","    out = self.fc(out[:, -1, :]) #最後の出力 #out.size()=(batch_size, output_size)\n","    return out\n","\n","  def init_hidden(self, device): #初期隠れ層\n","    hidden = torch.zeros(1, self.batch_size, self.hidden_size, device=device)\n","    return hidden"],"metadata":{"id":"ZMgZElkfOyMq","executionInfo":{"status":"ok","timestamp":1687936644888,"user_tz":-540,"elapsed":4654,"user":{"displayName":"周航旭","userId":"09485546673902671804"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset\n","\n","class CreateDataset(Dataset):\n","  def __init__(self, X, y, tokenizer):\n","    self.X = X\n","    self.y = y\n","    self.tokenizer = tokenizer\n","\n","  def __len__(self):  # len(Dataset)で返す値を指定\n","    return len(self.y)\n","\n","  def __getitem__(self, index):  # Dataset[index]で返す値を指定\n","    text = self.X[index]\n","    inputs = self.tokenizer(text)\n","\n","    return {\n","      'inputs': torch.tensor(inputs, dtype=torch.int64),\n","      'labels': torch.tensor(self.y[index], dtype=torch.int64)\n","    }\n","\n","#ラベルベクトルの作成\n","category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n","y_train = train['CATEGORY'].map(lambda x: category_dict[x]).values\n","y_valid = valid['CATEGORY'].map(lambda x: category_dict[x]).values\n","y_test = test['CATEGORY'].map(lambda x: category_dict[x]).values\n","\n","#Datasetの作成\n","dataset_train = CreateDataset(train['TITLE'], y_train, tokenizer)\n","dataset_valid = CreateDataset(valid['TITLE'], y_valid, tokenizer)\n","dataset_test = CreateDataset(test['TITLE'], y_test, tokenizer)\n","\n","print(f'len(Dataset)の出力: {len(dataset_train)}')\n","print('Dataset[index]の出力:')\n","for var in dataset_train[1]:\n","  print(f'  {var}: {dataset_train[1][var]}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k4UB5FUbl-sQ","executionInfo":{"status":"ok","timestamp":1687936646991,"user_tz":-540,"elapsed":307,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"7fbfcc13-e029-429b-9cc6-e32377b9077b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["len(Dataset)の出力: 10672\n","Dataset[index]の出力:\n","  inputs: tensor([  55,   59,  161,    4,    7,  234, 3530,   26,   97,  429])\n","  labels: 0\n"]}]},{"cell_type":"code","source":["#予測\n","#パラメータの設定\n","VOCAB_SIZE = len(set(word2id.values())) + 1  # 辞書のID数+paddingID\n","EMB_SIZE = 300\n","PADDING_IDX = len(set(word2id.values()))\n","OUTPUT_SIZE = 4\n","HIDDEN_SIZE = 50\n","\n","#rnnモデル\n","model = RNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, HIDDEN_SIZE)\n","\n","for i in range(10):\n"," X = dataset_train[i]['inputs']\n"," print(torch.softmax(model(X.unsqueeze(0)), dim=-1))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xB_w0k29ZH6F","executionInfo":{"status":"ok","timestamp":1687936650345,"user_tz":-540,"elapsed":283,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"c233e9c9-6605-4b31-9bfa-5ec905945a72"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[0.2490, 0.3425, 0.1677, 0.2408]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.1951, 0.1784, 0.4065, 0.2201]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3486, 0.3250, 0.1485, 0.1779]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.1983, 0.2109, 0.1453, 0.4455]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.1949, 0.2472, 0.3302, 0.2276]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3171, 0.2066, 0.1295, 0.3469]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2367, 0.3316, 0.2403, 0.1914]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2151, 0.1901, 0.1921, 0.4027]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.3488, 0.1462, 0.2142, 0.2908]], grad_fn=<SoftmaxBackward0>)\n","tensor([[0.2713, 0.1708, 0.2654, 0.2925]], grad_fn=<SoftmaxBackward0>)\n"]}]},{"cell_type":"markdown","source":["**knock82**"],"metadata":{"id":"LeVxE7oYcsCh"}},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from torch import optim\n","\n","##損失と正解率の計算\n","def calculate_loss_and_accuracy(model, dataset, device=None, criterion=None):\n","  dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n","  loss = 0.0\n","  total = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for data in dataloader:\n","      inputs = data['inputs']\n","      labels = data['labels']\n","\n","      outputs = model(inputs) #順伝播\n","\n","      if criterion != None: #損失関数\n","        loss += criterion(outputs, labels).item()\n","\n","      pred = torch.argmax(outputs, dim=-1) #accuracy\n","      total += len(inputs)\n","      correct += (pred == labels).sum().item()\n","\n","  return loss / len(dataset), correct / total"],"metadata":{"id":"edz_5EVPkxo2","executionInfo":{"status":"ok","timestamp":1687936652655,"user_tz":-540,"elapsed":238,"user":{"displayName":"周航旭","userId":"09485546673902671804"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["#学習を実行し、損失・正解率を返す\n","def train_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, num_epochs, collate_fn=None, device=None):\n","  #dataloaderを作る\n","  dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n","  dataloader_valid = DataLoader(dataset_valid, batch_size=1, shuffle=False)\n","\n","  #スケジューラの設定\n","  scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs, eta_min=1e-5, last_epoch=-1)\n","\n","  #学習\n","  for epoch in range(num_epochs):\n","\n","    model.train() #訓練モードに設定\n","    for data in dataloader_train:\n","      optimizer.zero_grad() #勾配をゼロで初期化\n","\n","      #順伝播+誤差逆伝播+重み更新\n","      inputs = data['inputs']\n","      labels = data['labels']\n","      outputs = model(inputs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","    model.eval() #評価モードに設定\n","\n","    #損失と正解率\n","    loss_train, acc_train = calculate_loss_and_accuracy(model, dataset_train, device, criterion=criterion)\n","    loss_valid, acc_valid = calculate_loss_and_accuracy(model, dataset_valid, device, criterion=criterion)\n","\n","    #チェックポイントの保存\n","    torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n","    print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}')\n","\n","    if epoch > 10: #stop\n","      break\n","\n","    scheduler.step() #スケジューラを1step進める\n"],"metadata":{"id":"rDlWhGanBQvp","executionInfo":{"status":"ok","timestamp":1687936655349,"user_tz":-540,"elapsed":7,"user":{"displayName":"周航旭","userId":"09485546673902671804"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#parameters\n","VOCAB_SIZE = len(set(word2id.values())) + 1\n","EMB_SIZE = 300\n","PADDING_IDX = len(set(word2id.values()))\n","OUTPUT_SIZE = 4\n","HIDDEN_SIZE = 50\n","LEARNING_RATE = 1e-3\n","BATCH_SIZE = 1\n","NUM_EPOCHS = 10\n","\n","model = RNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, HIDDEN_SIZE) #model\n","criterion = nn.CrossEntropyLoss() #損失関数\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n","\n","#モデルの学習\n","train_model(dataset_train, dataset_valid, BATCH_SIZE, model, criterion, optimizer, NUM_EPOCHS)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7cHraKSPBXZU","executionInfo":{"status":"ok","timestamp":1687937032410,"user_tz":-540,"elapsed":374055,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"6f8c5779-d023-4b92-c441-5d1f1b08f6ae"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.1025, accuracy_train: 0.5272, loss_valid: 1.1351, accuracy_valid: 0.5007\n","epoch: 2, loss_train: 1.0191, accuracy_train: 0.5878, loss_valid: 1.0795, accuracy_valid: 0.5555\n","epoch: 3, loss_train: 0.9046, accuracy_train: 0.6596, loss_valid: 0.9852, accuracy_valid: 0.6259\n","epoch: 4, loss_train: 0.7693, accuracy_train: 0.7277, loss_valid: 0.8776, accuracy_valid: 0.6897\n","epoch: 5, loss_train: 0.6969, accuracy_train: 0.7510, loss_valid: 0.8413, accuracy_valid: 0.7069\n","epoch: 6, loss_train: 0.6138, accuracy_train: 0.7819, loss_valid: 0.7752, accuracy_valid: 0.7354\n","epoch: 7, loss_train: 0.5731, accuracy_train: 0.7955, loss_valid: 0.7469, accuracy_valid: 0.7444\n","epoch: 8, loss_train: 0.5302, accuracy_train: 0.8087, loss_valid: 0.7133, accuracy_valid: 0.7571\n","epoch: 9, loss_train: 0.5167, accuracy_train: 0.8136, loss_valid: 0.7076, accuracy_valid: 0.7534\n","epoch: 10, loss_train: 0.5100, accuracy_train: 0.8140, loss_valid: 0.7034, accuracy_valid: 0.7549\n"]}]},{"cell_type":"markdown","source":["**knock83**"],"metadata":{"id":"ySntKUHe13C3"}},{"cell_type":"code","source":["##系列の長さに基づいて自動的にパディングが行われます\n","class Padsequence():\n","  def __init__(self, padding_idx):\n","    self.padding_idx = padding_idx\n","\n","  def __call__(self, batch): #ミニバッチを取り出す\n","    sorted_batch = sorted(batch, key=lambda x: x['inputs'].shape[0], reverse=True)\n","    sequences = [x['inputs'] for x in sorted_batch]\n","    sequences_padded = torch.nn.utils.rnn.pad_sequence(sequences, batch_first=True, padding_value=self.padding_idx)\n","    labels = torch.LongTensor([x['labels'] for x in sorted_batch])\n","\n","    return {'inputs': sequences_padded, 'labels': labels}"],"metadata":{"id":"kdOj1_P614Zo","executionInfo":{"status":"ok","timestamp":1687937039295,"user_tz":-540,"elapsed":312,"user":{"displayName":"周航旭","userId":"09485546673902671804"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["##損失と正解率の計算\n","def calculate_loss_and_accuracy(model, dataset, device=None, criterion=None):\n","  dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n","  loss = 0.0\n","  total = 0\n","  correct = 0\n","  with torch.no_grad():\n","    for data in dataloader:\n","      inputs = data['inputs'].to(device)\n","      labels = data['labels'].to(device)\n","\n","      outputs = model(inputs) #順伝播\n","\n","      if criterion != None: #損失関数\n","        loss += criterion(outputs, labels).item()\n","\n","      pred = torch.argmax(outputs, dim=-1) #accuracy\n","      total += len(inputs)\n","      correct += (pred == labels).sum().item()\n","\n","  return loss / len(dataset), correct / total"],"metadata":{"id":"incNIY9x8ugc","executionInfo":{"status":"ok","timestamp":1687939258332,"user_tz":-540,"elapsed":301,"user":{"displayName":"周航旭","userId":"09485546673902671804"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["#学習を実行し、損失・正解率を返す GPUを使う\n","def train_model(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, num_epochs, collate_fn=None, device=None):\n","  model.to(device)\n","\n","  #dataloaderを作る\n","  dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n","  dataloader_valid = DataLoader(dataset_valid, batch_size=1, shuffle=False)\n","\n","  #スケジューラの設定\n","  scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epochs, eta_min=1e-5, last_epoch=-1)\n","\n","  #学習\n","  for epoch in range(num_epochs):\n","    model.train() #訓練モードに設定\n","    for data in dataloader_train:\n","      optimizer.zero_grad() #勾配をゼロで初期化\n","\n","      #順伝播+誤差逆伝播+重み更新\n","      inputs = data['inputs'].to(device)\n","      labels = data['labels'].to(device)\n","      outputs = model(inputs)\n","      loss = criterion(outputs, labels)\n","      loss.backward()\n","      optimizer.step()\n","\n","    model.eval() #評価モードに設定\n","\n","    #損失と正解率\n","    loss_train, acc_train = calculate_loss_and_accuracy(model, dataset_train, device, criterion=criterion)\n","    loss_valid, acc_valid = calculate_loss_and_accuracy(model, dataset_valid, device, criterion=criterion)\n","\n","    #チェックポイントの保存\n","    torch.save({'epoch': epoch, 'model_state_dict': model.state_dict(), 'optimizer_state_dict': optimizer.state_dict()}, f'checkpoint{epoch + 1}.pt')\n","    print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, accuracy_train: {acc_train:.4f}, loss_valid: {loss_valid:.4f}, accuracy_valid: {acc_valid:.4f}')\n","\n","    if epoch > 10: #stop\n","      break\n","\n","    scheduler.step() #スケジューラを1step進める\n"],"metadata":{"id":"XiDmrGir7yZn","executionInfo":{"status":"ok","timestamp":1687939263245,"user_tz":-540,"elapsed":301,"user":{"displayName":"周航旭","userId":"09485546673902671804"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["#parameters\n","VOCAB_SIZE = len(set(word2id.values())) + 1\n","EMB_SIZE = 300\n","PADDING_IDX = len(set(word2id.values()))\n","OUTPUT_SIZE = 4\n","HIDDEN_SIZE = 50\n","LEARNING_RATE = 5e-2\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 10\n","\n","model = RNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, HIDDEN_SIZE) #model\n","criterion = nn.CrossEntropyLoss() #損失関数\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n","device = torch.device('cuda')\n","\n","#モデルの学習\n","train_model(dataset_train, dataset_valid, BATCH_SIZE, model, criterion, optimizer, NUM_EPOCHS, collate_fn=Padsequence(PADDING_IDX), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cNEsEUiL6_xQ","executionInfo":{"status":"ok","timestamp":1687939370705,"user_tz":-540,"elapsed":104996,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"9ebd9dfa-882b-4758-d2aa-7e19e7ba189f"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.2501, accuracy_train: 0.4097, loss_valid: 1.2362, accuracy_valid: 0.4325\n","epoch: 2, loss_train: 1.1827, accuracy_train: 0.4770, loss_valid: 1.1750, accuracy_valid: 0.4925\n","epoch: 3, loss_train: 1.1303, accuracy_train: 0.5284, loss_valid: 1.1455, accuracy_valid: 0.5135\n","epoch: 4, loss_train: 1.0680, accuracy_train: 0.5934, loss_valid: 1.1185, accuracy_valid: 0.5525\n","epoch: 5, loss_train: 0.9469, accuracy_train: 0.6845, loss_valid: 0.9872, accuracy_valid: 0.6492\n","epoch: 6, loss_train: 0.9487, accuracy_train: 0.6744, loss_valid: 1.0336, accuracy_valid: 0.6057\n","epoch: 7, loss_train: 0.8413, accuracy_train: 0.7220, loss_valid: 0.9294, accuracy_valid: 0.6657\n","epoch: 8, loss_train: 0.7838, accuracy_train: 0.7451, loss_valid: 0.8814, accuracy_valid: 0.6897\n","epoch: 9, loss_train: 0.7677, accuracy_train: 0.7489, loss_valid: 0.8727, accuracy_valid: 0.6934\n","epoch: 10, loss_train: 0.7742, accuracy_train: 0.7441, loss_valid: 0.8822, accuracy_valid: 0.6852\n"]}]},{"cell_type":"markdown","source":["**knock84**"],"metadata":{"id":"AIIGTUrW8iwK"}},{"cell_type":"code","source":["import numpy as np\n","from gensim.models import KeyedVectors\n","\n","#学習済みモデルのロード\n","model = KeyedVectors.load_word2vec_format('drive/MyDrive/chapter09/GoogleNews-vectors-negative300.bin.gz', binary=True)\n","\n","#学習済み単語ベクトルの取得\n","VOCAB_SIZE = len(set(word2id.values())) + 1\n","EMB_SIZE = 300 #単語ベクトルの次元数\n","weights = np.zeros((VOCAB_SIZE, EMB_SIZE)) #学習済み単語ベクトルを格納する\n","words_in_pretrained = 0\n","for i, word in enumerate(word2id.keys()):\n","  try:\n","    weights[i] = model[word]\n","    words_in_pretrained += 1 #学習済み単語ベクトルの単語の数\n","  except KeyError:\n","    weights[i] = np.random.normal(scale=0.4, size=(EMB_SIZE,)) #ランダムな値で行を初期化する\n","weights = torch.from_numpy(weights.astype((np.float32))) #numpy配列からtorch.Tensorに変換\n","\n","print(f'学習済みベクトル利用単語数: {words_in_pretrained} / {VOCAB_SIZE}')\n","print(weights.size())"],"metadata":{"id":"Dvbn9Zfo-NO2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1687940806037,"user_tz":-540,"elapsed":65725,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"bdbfbe56-cd3e-4928-c1b9-7c85866a23db"},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["学習済みベクトル利用単語数: 6514 / 6667\n","torch.Size([6667, 300])\n"]}]},{"cell_type":"code","source":["class RNN(nn.Module):\n","  def __init__(self, vocab_size, emb_size, padding_idx, output_size, hidden_size, num_layers, emb_weights=None, bidirectional=False):\n","    super().__init__()\n","    self.hidden_size = hidden_size #隠れ状態の次元数\n","    self.num_layers = num_layers\n","    self.num_directions = bidirectional + 1  #単方向：1、双方向：2\n","    if emb_weights != None:  #emb_weights: 埋め込み層の重み\n","      self.emb = nn.Embedding.from_pretrained(emb_weights, padding_idx=padding_idx)\n","    else:\n","      self.emb = nn.Embedding(vocab_size, emb_size, padding_idx=padding_idx)\n","    self.rnn = nn.RNN(emb_size, hidden_size, num_layers, nonlinearity='tanh', bidirectional=bidirectional, batch_first=True)\n","    self.fc = nn.Linear(hidden_size * self.num_directions, output_size) #線形\n","\n","  def forward(self, x): #順方向の計算が行う\n","    self.batch_size = x.size()[0]\n","    hidden = self.init_hidden(x.device)  #h0のゼロベクトルを作成\n","    emb = self.emb(x)\n","    #emb.size() = (batch_size, seq_len, emb_size)\n","    out, hidden = self.rnn(emb, hidden)\n","    #out.size() = (batch_size, seq_len, hidden_size * num_directions)\n","    out = self.fc(out[:, -1, :])\n","    #out.size() = (batch_size, output_size)\n","    return out\n","\n","  def init_hidden(self, device): #RNNの初期隠れ状態をゼロベクトルで初期化\n","    hidden = torch.zeros(self.num_layers * self.num_directions, self.batch_size, self.hidden_size, device=device)\n","    return hidden"],"metadata":{"id":"ymZnniZH5Q88","executionInfo":{"status":"ok","timestamp":1687940868916,"user_tz":-540,"elapsed":424,"user":{"displayName":"周航旭","userId":"09485546673902671804"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["# パラメータの設定\n","VOCAB_SIZE = len(set(word2id.values())) + 1\n","EMB_SIZE = 300\n","PADDING_IDX = len(set(word2id.values()))\n","OUTPUT_SIZE = 4\n","HIDDEN_SIZE = 50\n","NUM_LAYERS = 1\n","LEARNING_RATE = 5e-2\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 10\n","\n","model = RNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, emb_weights=weights)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n","device = torch.device('cuda')\n","\n","# モデルの学習\n","train_model(dataset_train, dataset_valid, BATCH_SIZE, model, criterion, optimizer, NUM_EPOCHS, collate_fn=Padsequence(PADDING_IDX), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R86QaHqlHHUh","executionInfo":{"status":"ok","timestamp":1687940983934,"user_tz":-540,"elapsed":111788,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"30879828-0610-49a4-dbe1-21ff2c3b8c98"},"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.2088, accuracy_train: 0.4181, loss_valid: 1.2456, accuracy_valid: 0.4100\n","epoch: 2, loss_train: 1.1596, accuracy_train: 0.5013, loss_valid: 1.1949, accuracy_valid: 0.4805\n","epoch: 3, loss_train: 1.1097, accuracy_train: 0.5735, loss_valid: 1.1500, accuracy_valid: 0.5487\n","epoch: 4, loss_train: 1.1729, accuracy_train: 0.5436, loss_valid: 1.2139, accuracy_valid: 0.5315\n","epoch: 5, loss_train: 1.1181, accuracy_train: 0.5813, loss_valid: 1.1750, accuracy_valid: 0.5600\n","epoch: 6, loss_train: 1.0581, accuracy_train: 0.6095, loss_valid: 1.1249, accuracy_valid: 0.5795\n","epoch: 7, loss_train: 0.9887, accuracy_train: 0.6362, loss_valid: 1.0575, accuracy_valid: 0.6079\n","epoch: 8, loss_train: 0.9648, accuracy_train: 0.6453, loss_valid: 1.0312, accuracy_valid: 0.6012\n","epoch: 9, loss_train: 0.9645, accuracy_train: 0.6436, loss_valid: 1.0309, accuracy_valid: 0.6019\n","epoch: 10, loss_train: 0.9704, accuracy_train: 0.6422, loss_valid: 1.0357, accuracy_valid: 0.6019\n"]}]},{"cell_type":"markdown","source":["**knock85**"],"metadata":{"id":"W3UrBX-JHceF"}},{"cell_type":"code","source":["#parameters\n","VOCAB_SIZE = len(set(word2id.values())) + 1\n","EMB_SIZE = 300\n","PADDING_IDX = len(set(word2id.values()))\n","OUTPUT_SIZE = 4\n","HIDDEN_SIZE = 50\n","NUM_LAYERS = 2\n","LEARNING_RATE = 5e-2\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 10\n","\n","model = RNN(VOCAB_SIZE, EMB_SIZE, PADDING_IDX, OUTPUT_SIZE, HIDDEN_SIZE, NUM_LAYERS, emb_weights=weights, bidirectional=True)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=LEARNING_RATE)\n","device = torch.device('cuda')\n","\n","#モデルの学習\n","train_model(dataset_train, dataset_valid, BATCH_SIZE, model, criterion, optimizer, NUM_EPOCHS, collate_fn=Padsequence(PADDING_IDX), device=device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"G1Bh31MUOcxc","executionInfo":{"status":"ok","timestamp":1687942866511,"user_tz":-540,"elapsed":127718,"user":{"displayName":"周航旭","userId":"09485546673902671804"}},"outputId":"280a23c9-2909-47cf-dd0c-7e379344900b"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["epoch: 1, loss_train: 1.1617, accuracy_train: 0.4253, loss_valid: 1.1683, accuracy_valid: 0.4183\n","epoch: 2, loss_train: 1.1446, accuracy_train: 0.4884, loss_valid: 1.1841, accuracy_valid: 0.4610\n","epoch: 3, loss_train: 1.0685, accuracy_train: 0.5706, loss_valid: 1.1294, accuracy_valid: 0.5315\n","epoch: 4, loss_train: 1.0302, accuracy_train: 0.5933, loss_valid: 1.0909, accuracy_valid: 0.5600\n","epoch: 5, loss_train: 0.9864, accuracy_train: 0.6228, loss_valid: 1.0532, accuracy_valid: 0.5772\n","epoch: 6, loss_train: 0.9340, accuracy_train: 0.6477, loss_valid: 0.9913, accuracy_valid: 0.6117\n","epoch: 7, loss_train: 0.9235, accuracy_train: 0.6512, loss_valid: 0.9841, accuracy_valid: 0.6162\n","epoch: 8, loss_train: 0.9150, accuracy_train: 0.6554, loss_valid: 0.9756, accuracy_valid: 0.6252\n","epoch: 9, loss_train: 0.9047, accuracy_train: 0.6528, loss_valid: 0.9669, accuracy_valid: 0.6222\n","epoch: 10, loss_train: 0.9071, accuracy_train: 0.6501, loss_valid: 0.9680, accuracy_valid: 0.6222\n"]}]}]}