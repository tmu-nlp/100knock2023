{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kWskn0UETe0o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "1c09f17a-b470-45d9-b558-a984d272f775"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J4rQmBzDUL6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "9C8wy137U1nN",
        "outputId": "f4fb0ae6-d816-4152-8dfc-4a4bbb98682f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
            "To: /content/data.bin.gz\n",
            "100%|██████████| 1.65G/1.65G [00:10<00:00, 153MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data.bin.gz'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import gdown\n",
        "\n",
        "url = 'https://drive.google.com/uc?id=0B7XkCwpI5KDYNlNUTTlSS21pQmM'\n",
        "output = 'data.bin.gz'\n",
        "\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "3gSBpkJOTJeK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba1cdd7-9138-44fb-b467-9132e91beb21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data.bin  drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
        "!unzip NewsAggregatorDataset.zip"
      ],
      "metadata": {
        "id": "2or7_zuYTqql",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aedf793b-a859-4368-c888-917e6b1782fc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-19 06:22:18--  https://archive.ics.uci.edu/ml/machine-learning-databases/00359/NewsAggregatorDataset.zip\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘NewsAggregatorDataset.zip’\n",
            "\n",
            "NewsAggregatorDatas     [     <=>            ]  27.87M  27.5MB/s    in 1.0s    \n",
            "\n",
            "2023-06-19 06:22:19 (27.5 MB/s) - ‘NewsAggregatorDataset.zip’ saved [29224203]\n",
            "\n",
            "Archive:  NewsAggregatorDataset.zip\n",
            "  inflating: 2pageSessions.csv       \n",
            "   creating: __MACOSX/\n",
            "  inflating: __MACOSX/._2pageSessions.csv  \n",
            "  inflating: newsCorpora.csv         \n",
            "  inflating: __MACOSX/._newsCorpora.csv  \n",
            "  inflating: readme.txt              \n",
            "  inflating: __MACOSX/._readme.txt   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -e 's/\"/'\\''/g' ./newsCorpora.csv > ./newsCorpora_re.csv"
      ],
      "metadata": {
        "id": "UXIDhwA0Ua0V"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKOtgsojUcB3",
        "outputId": "80b6683d-0512-4ea8-86c6-128f35b0cd9b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2pageSessions.csv  \u001b[0m\u001b[01;34m__MACOSX\u001b[0m/                  newsCorpora_re.csv\n",
            "data.bin           NewsAggregatorDataset.zip  readme.txt\n",
            "\u001b[01;34mdrive\u001b[0m/             newsCorpora.csv            \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# データの読込\n",
        "df = pd.read_csv('./newsCorpora_re.csv', header=None, sep='\\t', names=['ID', 'TITLE', 'URL', 'PUBLISHER', 'CATEGORY', 'STORY', 'HOSTNAME', 'TIMESTAMP'])\n",
        "\n",
        "# データの抽出\n",
        "df = df.loc[df['PUBLISHER'].isin(['Reuters', 'Huffington Post', 'Businessweek', 'Contactmusic.com', 'Daily Mail']), ['TITLE', 'CATEGORY']]\n",
        "\n",
        "# データの分割\n",
        "train, valid_test = train_test_split(df, test_size=0.2, shuffle=True, random_state=123, stratify=df['CATEGORY'])\n",
        "valid, test = train_test_split(valid_test, test_size=0.5, shuffle=True, random_state=123, stratify=valid_test['CATEGORY'])\n",
        "\n",
        "# 事例数の確認\n",
        "print('【学習データ】')\n",
        "print(train['CATEGORY'].value_counts())\n",
        "print('【検証データ】')\n",
        "print(valid['CATEGORY'].value_counts())\n",
        "print('【評価データ】')\n",
        "print(test['CATEGORY'].value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ4rb0JxUdLT",
        "outputId": "bf3c1476-8cf6-444a-bbba-719b6a5982f5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "【学習データ】\n",
            "b    4501\n",
            "e    4235\n",
            "t    1220\n",
            "m     728\n",
            "Name: CATEGORY, dtype: int64\n",
            "【検証データ】\n",
            "b    563\n",
            "e    529\n",
            "t    153\n",
            "m     91\n",
            "Name: CATEGORY, dtype: int64\n",
            "【評価データ】\n",
            "b    563\n",
            "e    530\n",
            "t    152\n",
            "m     91\n",
            "Name: CATEGORY, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown\n",
        "from gensim.models import KeyedVectors\n",
        "\n",
        "model = KeyedVectors.load_word2vec_format('data.bin.gz', binary=True)"
      ],
      "metadata": {
        "id": "ZTVFBYqfVC7b"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "import torch\n",
        "\n",
        "def transform_w2v(text):\n",
        "  table = str.maketrans(string.punctuation, ' '*len(string.punctuation))\n",
        "  words = text.translate(table).split()  # 記号をスペースに置換後、スペースで分割してリスト化\n",
        "  vec = [model[word] for word in words if word in model]  # 1語ずつベクトル化\n",
        "\n",
        "  return torch.tensor(sum(vec) / len(vec))  # 平均ベクトルをTensor型に変換して出力"
      ],
      "metadata": {
        "id": "HtRrTQjzWYJA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 特徴ベクトルの作成\n",
        "X_train = torch.stack([transform_w2v(text) for text in train['TITLE']])\n",
        "X_valid = torch.stack([transform_w2v(text) for text in valid['TITLE']])\n",
        "X_test = torch.stack([transform_w2v(text) for text in test['TITLE']])\n",
        "\n",
        "print(X_train.size())\n",
        "print(X_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CGHmYUj6Wh5_",
        "outputId": "c86f2d8d-6979-4f00-b22a-ca17f416a175"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10684, 300])\n",
            "tensor([[ 0.0837,  0.0056,  0.0068,  ...,  0.0751,  0.0433, -0.0868],\n",
            "        [ 0.0272,  0.0266, -0.0947,  ..., -0.1046, -0.0489, -0.0092],\n",
            "        [ 0.0577, -0.0159, -0.0780,  ..., -0.0421,  0.1229,  0.0876],\n",
            "        ...,\n",
            "        [ 0.0392, -0.0052,  0.0686,  ..., -0.0175,  0.0061, -0.0224],\n",
            "        [ 0.0798,  0.1017,  0.1066,  ..., -0.0752,  0.0623,  0.1138],\n",
            "        [ 0.1664,  0.0451,  0.0508,  ..., -0.0531, -0.0183, -0.0039]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ラベルベクトルの作成\n",
        "category_dict = {'b': 0, 't': 1, 'e':2, 'm':3}\n",
        "y_train = torch.tensor(train['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "y_valid = torch.tensor(valid['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "y_test = torch.tensor(test['CATEGORY'].map(lambda x: category_dict[x]).values)\n",
        "\n",
        "print(y_train.size())\n",
        "print(y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9_CmCpGWlTu",
        "outputId": "2e91c19f-46b0-46f4-db8e-6f6690e0667c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10684])\n",
            "tensor([0, 1, 3,  ..., 0, 3, 2])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 保存\n",
        "torch.save(X_train, 'X_train.pt')\n",
        "torch.save(X_valid, 'X_valid.pt')\n",
        "torch.save(X_test, 'X_test.pt')\n",
        "torch.save(y_train, 'y_train.pt')\n",
        "torch.save(y_valid, 'y_valid.pt')\n",
        "torch.save(y_test, 'y_test.pt')"
      ],
      "metadata": {
        "id": "ZEJX--amWpXf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "class SLPNet(nn.Module):\n",
        "  def __init__(self, input_size, output_size):\n",
        "    super().__init__()\n",
        "    self.fc = nn.Linear(input_size, output_size, bias=False)\n",
        "    nn.init.normal_(self.fc.weight, 0.0, 1.0)  # 正規乱数で重みを初期化\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "RzcKcVEVWtic"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SLPNet(300, 4)  # 単層ニューラルネットワークの初期化\n",
        "y_hat_1 = torch.softmax(model(X_train[:1]), dim=-1)\n",
        "print(y_hat_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jUG38HRjWwPP",
        "outputId": "339fb9a7-e022-46cb-8ba0-de69643e0d57"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2675, 0.3408, 0.0668, 0.3249]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_hat = torch.softmax(model.forward(X_train[:4]), dim=-1)\n",
        "print(Y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4AxbKv80WyvG",
        "outputId": "cbe3d59a-dc91-43a8-e5ec-4fa3d68ad36b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2675, 0.3408, 0.0668, 0.3249],\n",
            "        [0.0551, 0.4446, 0.2316, 0.2688],\n",
            "        [0.1773, 0.6784, 0.1386, 0.0057],\n",
            "        [0.1735, 0.6181, 0.1489, 0.0595]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "S32cRIMyW0R4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l_1 = criterion(model(X_train[:1]), y_train[:1])  # 入力ベクトルはsoftmax前の値\n",
        "model.zero_grad()  # 勾配をゼロで初期化\n",
        "l_1.backward()  # 勾配を計算\n",
        "print(f'損失: {l_1:.4f}')\n",
        "print(f'勾配:\\n{model.fc.weight.grad}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqYgkKotW1-t",
        "outputId": "17d251a2-bd6b-4669-9763-da8eb1d25438"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失: 1.3185\n",
            "勾配:\n",
            "tensor([[-0.0613, -0.0041, -0.0050,  ..., -0.0550, -0.0317,  0.0636],\n",
            "        [ 0.0285,  0.0019,  0.0023,  ...,  0.0256,  0.0148, -0.0296],\n",
            "        [ 0.0056,  0.0004,  0.0005,  ...,  0.0050,  0.0029, -0.0058],\n",
            "        [ 0.0272,  0.0018,  0.0022,  ...,  0.0244,  0.0141, -0.0282]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "l = criterion(model(X_train[:4]), y_train[:4])\n",
        "model.zero_grad()\n",
        "l.backward()\n",
        "print(f'損失: {l:.4f}')\n",
        "print(f'勾配:\\n{model.fc.weight.grad}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfVtgWISW6FJ",
        "outputId": "03536761-ec47-4d6a-b824-f7c419ffff4f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "損失: 2.3006\n",
            "勾配:\n",
            "tensor([[-0.0148,  0.0008, -0.0033,  ..., -0.0177, -0.0015,  0.0188],\n",
            "        [ 0.0045,  0.0018,  0.0101,  ...,  0.0117,  0.0373,  0.0056],\n",
            "        [ 0.0168, -0.0095, -0.0213,  ..., -0.0034, -0.0061,  0.0054],\n",
            "        [-0.0065,  0.0069,  0.0145,  ...,  0.0093, -0.0297, -0.0298]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class NewsDataset(Dataset):\n",
        "  def __init__(self, X, y):  # datasetの構成要素を指定\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):  # len(dataset)で返す値を指定\n",
        "    return len(self.y)\n",
        "\n",
        "  def __getitem__(self, idx):  # dataset[idx]で返す値を指定\n",
        "    return [self.X[idx], self.y[idx]]"
      ],
      "metadata": {
        "id": "cqgmB_VbXHPk"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Datasetの作成\n",
        "dataset_train = NewsDataset(X_train, y_train)\n",
        "dataset_valid = NewsDataset(X_valid, y_valid)\n",
        "dataset_test = NewsDataset(X_test, y_test)\n",
        "\n",
        "# Dataloaderの作成\n",
        "dataloader_train = DataLoader(dataset_train, batch_size=1, shuffle=True)\n",
        "dataloader_valid = DataLoader(dataset_valid, batch_size=len(dataset_valid), shuffle=False)\n",
        "dataloader_test = DataLoader(dataset_test, batch_size=len(dataset_test), shuffle=False)"
      ],
      "metadata": {
        "id": "1YFxQxFNXJTZ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# モデルの定義\n",
        "model = SLPNet(300, 4)\n",
        "\n",
        "# 損失関数の定義\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# オプティマイザの定義\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
        "\n",
        "# 学習\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  # 訓練モードに設定\n",
        "  model.train()\n",
        "  loss_train = 0.0\n",
        "  for i, (inputs, labels) in enumerate(dataloader_train):\n",
        "    # 勾配をゼロで初期化\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 順伝播 + 誤差逆伝播 + 重み更新\n",
        "    outputs = model(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 損失を記録\n",
        "    loss_train += loss.item()\n",
        "\n",
        "  # バッチ単位の平均損失計算\n",
        "  loss_train = loss_train / i\n",
        "\n",
        "  # 検証データの損失計算\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    inputs, labels = next(iter(dataloader_valid))\n",
        "    outputs = model(inputs)\n",
        "    loss_valid = criterion(outputs, labels)\n",
        "\n",
        "  # ログを出力\n",
        "  print(f'epoch: {epoch + 1}, loss_train: {loss_train:.4f}, loss_valid: {loss_valid:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NVen1FfIXZwi",
        "outputId": "f52779c8-c0e6-4bae-e36b-43290a667dde"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss_train: 0.4641, loss_valid: 0.3541\n",
            "epoch: 2, loss_train: 0.3109, loss_valid: 0.3283\n",
            "epoch: 3, loss_train: 0.2813, loss_valid: 0.3164\n",
            "epoch: 4, loss_train: 0.2653, loss_valid: 0.3150\n",
            "epoch: 5, loss_train: 0.2562, loss_valid: 0.3089\n",
            "epoch: 6, loss_train: 0.2494, loss_valid: 0.3049\n",
            "epoch: 7, loss_train: 0.2437, loss_valid: 0.3074\n",
            "epoch: 8, loss_train: 0.2393, loss_valid: 0.3123\n",
            "epoch: 9, loss_train: 0.2358, loss_valid: 0.3071\n",
            "epoch: 10, loss_train: 0.2334, loss_valid: 0.3054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_accuracy(model, loader):\n",
        "  model.eval()\n",
        "  total = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in loader:\n",
        "      outputs = model(inputs)\n",
        "      pred = torch.argmax(outputs, dim=-1)\n",
        "      total += len(inputs)\n",
        "      correct += (pred == labels).sum().item()\n",
        "\n",
        "  return correct / total"
      ],
      "metadata": {
        "id": "nzGJedmUXdz2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_train = calculate_accuracy(model, dataloader_train)\n",
        "acc_test = calculate_accuracy(model, dataloader_test)\n",
        "print(f'正解率（学習データ）：{acc_train:.3f}')\n",
        "print(f'正解率（評価データ）：{acc_test:.3f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkkoRcFLXica",
        "outputId": "262ec6b8-e6d1-4a97-8586-7d16afe6ed35"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "正解率（学習データ）：0.925\n",
            "正解率（評価データ）：0.902\n"
          ]
        }
      ]
    }
  ]
}